{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Note-Lec3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "clyKDmZDp0RB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TOPICS: CNNs and transfer learning\n",
        "* From scratch\n",
        "* Reusing a pretrained model\n",
        "* Fine-tuning\n",
        "* Data augmentation\n",
        "* Feature visualization"
      ]
    },
    {
      "metadata": {
        "id": "PCo5UrbRrvwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolution\n",
        "sliding a filter across an image <br>\n",
        "在python中：<br>\n",
        "result = scipy.signal.convolve2d(img, kernel, 'same')\n",
        "\n",
        "Filter的作用：np.tensordot(img, kernel).<br>\n",
        "比如3\\*3的kernel, np.tensordot(A, B) = $\\sum_{i=1}^3\\sum_{j=1}^3A_{ij}B_{ij}$.\n",
        "\n",
        "所以4\\*4的img, 3\\*3的kernel, stride 1, 会变成2\\*2的结果。\n",
        "\n",
        "这是2D，3D也是一样。都是点乘之后变成1个值。"
      ]
    },
    {
      "metadata": {
        "id": "jIsKueRc3mj8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ]
    },
    {
      "metadata": {
        "id": "nkfxPeON4NEo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Filters\n",
        "More filters, more output channels.\n",
        "* 每个filter learn一组weights。 每个filter 都连上每个input channel.\n",
        "* An output channel is called a **feature map**\n",
        "\n",
        "1d convolution. <br>\n",
        "weights是1\\*\\*depth. 不改变width&heights, 但是把depth压缩到1.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "04Y91Jfg5h7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Max pooling\n",
        "还有average pooling, 注意n\\*n的格子是把n^2个格子和除以n.\n",
        "\n",
        "### Padding.\n",
        "* 保持filter之后spatial size.<br>\n",
        "* padding = 'same'是有，padding='valid'是no padding.\n",
        "* padding='same'是在周围垫上一圈0\n",
        "\n",
        "### Stride\n",
        "一次滑动的步长。可以通过它来downsize image.不过现在通常用pooling"
      ]
    },
    {
      "metadata": {
        "id": "wnI0MUb17jXv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Common Setup\n",
        "* One or more stacks of conv/pool layers with relu activation, followed by a flatten then one or two dense layers.\n",
        "* Feature maps become smaller spatially, and increase in depth.\n",
        "* Feature become more abstract but lose spatial information\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QkfX2OY28PEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 用CNN而不是DNN识别图像的原因\n",
        "* Efficiency. Dense需要多得多的parameter\n",
        "* Features must be detected separately at all locations."
      ]
    },
    {
      "metadata": {
        "id": "GbyxAq6b8_Ed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A typical CNN in keras\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3),\n",
        "                activation='relu',\n",
        "                input_shape=(28,28,1),\n",
        "                padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, kernel_size=(3,3),\n",
        "                activation='relu',\n",
        "                padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9lk7pgEyEfKC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 不同层\\# params\n",
        "* Dense: \\# params = (\\#input +1) \\* (\\#output)\n",
        "* Pooling: 0\n",
        "* Conv: \\# params = (filter size) \\* (filter size) \\* (input depth) \\* (\\#filters) +  (\\#filters) <br>\n",
        "第二项是bias, 1 per filter\n",
        "* Flatten: 0"
      ]
    },
    {
      "metadata": {
        "id": "cLsigpDsFYVT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 一些有名的model\n"
      ]
    },
    {
      "metadata": {
        "id": "4Jwy-2hmGBQn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## AlexNet\n",
        "ReLU; Use data augmentation; Dropout\n",
        "\n",
        "## VGG\n",
        "Simple, inefficient\n",
        "\n",
        "## Inception\n",
        "Efficient, 并且结构不再是conv/pool的堆积\n",
        "\n",
        "#### Global average pooling\n",
        "发现CNN中最后的dense layer含有最多的weights,并且对效率作用不大，所以在iinception paper里，它们在flatten dense之前，加了个global average pooling，极大减少parameter数量。\n",
        "\n",
        "#### Basic idea\n",
        "Instead of choosing which size of filter to use, run a few in parallel and let the network sort out which are useful.\n",
        "results merged by stacking depthwise.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "c-QLz0aQIIF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transfer learning\n",
        "**Idea**: knowledge (weights) learned on one task may be useful on another.\n",
        "* The base of a CNN learns a feature hierachy : edges -> shapes -> textures -> ... -> semantic features (eye detectors, ear detectors, etc)\n",
        "* Earlier features may generalize to other tasks (especially if trained on a large anount of data, say, ImageNet)\n",
        "\n",
        "通过可视化表示可发现，随着从底层向上，resolution下降。representation更多的说明图中是什么，而不是在哪儿。\n",
        "\n",
        "本来完整的CNN结构是，Input -> Trained convolutional base -> Trained classifier -> Prediction. \n",
        "这里我们保存trained convolutional base（来自大量训练的结果）,对当下的任务加上新的classifier (randomly initialized)再给出prediction。\n",
        "\n",
        "就可以train an accurate model with a small amount of data.\n",
        "\n",
        "可以fine-tune the top couple conv layers."
      ]
    },
    {
      "metadata": {
        "id": "48aNFEq1KI_4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ResNet\n",
        "<font color='red'>不太懂</font>\n",
        "\n",
        "Basic idea:\n",
        "* 152 layers deep\n",
        "* Problem with deep networks? <font color='red'>Vanishing gradient</font>\n",
        "* Mitigated by adding residual connections allowing signal to propagate the signal."
      ]
    },
    {
      "metadata": {
        "id": "KvQuLEPmKkg_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### YOLO\n",
        "Single forward pass object detection: 就是给张图，框框出物体和识别的label\n",
        "* Resize input to 448\\*448\n",
        "* Run a CNN\n",
        "* Output gives bounding boxes and class labels.\n",
        "\n",
        "Image is divided into S\\*S grid. For each grid cell, predict B bounding boxes and C class probabilities.\n",
        "\n",
        "**Predictions**: include x, y, w, h, confidence. (x,y) gives center of the bounding box. Confidence gives IOU (Intersection over union) estimate between predicted box and ground truth.\n",
        "\n",
        "最好retraining or fine tuning existing well known architecture for tasks, 而不是自己重新设计模型。"
      ]
    },
    {
      "metadata": {
        "id": "jJndgp3yM29E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "只能用于training set.\n"
      ]
    }
  ]
}