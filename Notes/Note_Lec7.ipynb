{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Note-Lec7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3y411PC53ThJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TOPICS: \n",
        "* Federated learning\n",
        "● Assignment #4\n",
        "* TensorFlow.js \n",
        "* Toxicity detector\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "51Y2tDjg4AQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Federated Learning\n",
        "Learning from decentralized data\n",
        "\n",
        "### Goal\n",
        "* Learn a shared model. Model is updated by a “federation” (collection) of participating devices.\n",
        "* Training data stays on device.\n",
        "* Inference happens locally, on device.\n",
        "\n",
        "### Server manages a shared model.\n",
        "* Server periodically send model (weights) to devices.\n",
        "* Devices send gradient updates to server.\n",
        "* Server averages these gradients, updates the model, and discards them.\n",
        " \n",
        "### Privacy issues\n",
        " Greatly improves, but does not guarantee privacy.\n",
        "* Gradient updates are (usually) more difficult to interpret than raw data, but still contain info about the user.\n",
        "* Server should discard gradient updates after they’re applied, but might not.\n",
        " \n",
        "### Improving privacy\n",
        "* Devices add random noise to updates (in aggregate, noise cancels out).\n",
        "* Device makes a bunch of updates, then sends average gradients.\n",
        "* Imagine a scheme where gradient updates are encrypted, and cannot be decrypted individually by the server (must be averaged somehow with a large batch of devices)."
      ]
    },
    {
      "metadata": {
        "id": "SYi9X8sRAf0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 邮件问题：\n",
        "\n",
        "## 1. Why use tf.data instead of NumPy for input pipelines? \n",
        " \n",
        "1. Ex 1: Prefetch.<br>\n",
        " * Without pipelining, the CPU and accelerator sit idle much of the time.\n",
        " * With pipelining, idle time is diminished.\n",
        " \n",
        "2. Ex 2: Parallel map.**Nah**<br>\n",
        "  *  This one is a little more obvious. Especially helpful when i/o bound (reading images off disk, or over the network), or when data augmentation is compute heavy.\n",
        "  * But, most of the time it’s not necessary.\n",
        "  Start optimizing only when you need to (if at all). Spend that energy elsewhere.\n",
        "  \n",
        " ## 2. TFRecords. \n",
        " P25. 基本不需要\n",
        " \n",
        " ## 3.  Word2Vec vs example code?\n",
        "<font color='red'>不懂</font>  Notes:\n",
        "* W2V in a nutshell: train a model to predict the next word in a sentence based on a short context\n",
        "window. In practice, choose the correct word vs. a small number of noisy word candidates for efficiency (rather than having a giant softmax layer where the classifier is forced to select the right word out of all possible choices).\n",
        "* When finished, extract the embedding weights and save / reuse in different tasks down the road, identically to example code.\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "0t7Ivc83BwFu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  TensorFlow.js\n",
        "<font color='red'>未完成</font>"
      ]
    },
    {
      "metadata": {
        "id": "OjXeeiU6CP1v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Toxicity Detector\n",
        "\n",
        "可能有的问题：\n",
        "* Bias in training data (could flag non toxic comments as toxic)\n",
        "* Could focus moderators attention to specific types of comments and away from others."
      ]
    },
    {
      "metadata": {
        "id": "_4OhmONT3PXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}