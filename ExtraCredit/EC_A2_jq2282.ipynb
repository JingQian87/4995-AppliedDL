{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EC-A2-jq2282.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Zd6e0W_dhjC-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# EC-A2: Classify QuickDraw images\n",
        "\n",
        "### Jing Qian (jq2282)\n",
        "\n",
        "If you’re up for more image classification, use the ​QuickDraw Loader​ to create a dataset of a bunch of different classes (you can use “animals” to start). Write a CNN to classify these images, and report your accuracy. How accurate of a model can you train to recognize 50 classes? 100? More?"
      ]
    },
    {
      "metadata": {
        "id": "25-aJX6mom9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 1. Load the Quick Draw dataset"
      ]
    },
    {
      "metadata": {
        "id": "acguyUXAqAKB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "Start with the group of animals with 42 classes\n",
        "\n",
        "Delete the class 'sea turtle' because of error"
      ]
    },
    {
      "metadata": {
        "id": "SWR59oOWhiUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import functools, itertools, json, os, re, textwrap\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from six.moves.urllib import request\n",
        "from xml.dom import minidom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RqFj3QsGhgg4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Retrieve list of classes.\n",
        "def list_bucket(bucket, regexp='.*'):\n",
        "    \"\"\"Returns a (filtered) list of Keys in specified GCE bucket.\"\"\"\n",
        "    keys = []\n",
        "    fh = request.urlopen('https://storage.googleapis.com/%s' % bucket)\n",
        "    content = minidom.parseString(fh.read())\n",
        "    for e in content.getElementsByTagName('Contents'):\n",
        "        key = e.getElementsByTagName('Key')[0].firstChild.data\n",
        "        if re.match(regexp, key):\n",
        "            keys.append(key)\n",
        "    return keys\n",
        "\n",
        "all_ndjsons = list_bucket('quickdraw_dataset', '.*ndjson$')\n",
        "# print('available: (%d)' % len(all_ndjsons))\n",
        "# print('\\n'.join(textwrap.wrap(\n",
        "#     ' '.join([key.split('/')[-1].split('.')[0] for key in all_ndjsons]),\n",
        "#     width=100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBJm5TS6pAoV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store all data locally in this directory.\n",
        "data_path = 'data'\n",
        "if not os.path.exists(data_path): \n",
        "  os.mkdir(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttP9oOKcpArd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start with the group of animals\n",
        "animals = ['bat', 'bird', 'butterfly', 'camel', 'cat', 'cow', 'crab',\n",
        "           'crocodile', 'dog', 'dolphin', 'duck', 'elephant', 'fish',\n",
        "           'frog', 'giraffe', 'hedgehog', 'horse', 'kangaroo', 'lion',\n",
        "           'lobster', 'monkey', 'mosquito', 'mouse', 'octopus', 'owl',\n",
        "           'panda', 'parrot', 'penguin', 'pig', 'rabbit', 'raccoon',\n",
        "           'rhinoceros', 'scorpion', 'shark', 'sheep',\n",
        "           'snail', 'spider', 'squirrel', 'teddy-bear', 'tiger',\n",
        "           'whale', 'zebra']\n",
        "\n",
        "classes, classes_name = animals, 'animals'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_W16MV_pAvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "1da6901f-2764-4c7b-c1f8-f39a5d6d0584"
      },
      "cell_type": "code",
      "source": [
        "# Download the chosen group.\n",
        "def valid_ndjson(filename):\n",
        "    \"\"\"Checks presence + completeness of .ndjson file.\"\"\"\n",
        "    try:\n",
        "        json.loads(open(filename).readlines()[-1])\n",
        "        return True\n",
        "    except (ValueError, IOError):\n",
        "        return False\n",
        "\n",
        "def retrieve(bucket, key, filename):\n",
        "    \"\"\"Returns a file specified by its Key from a GCE bucket.\"\"\"\n",
        "    url = 'https://storage.googleapis.com/%s/%s' % (bucket, key)\n",
        "    if not os.path.isfile(filename):\n",
        "        request.urlretrieve(url=url, filename=filename)\n",
        "    while not valid_ndjson(filename):\n",
        "        print('*** Corrupted download (%.2f MB), retrying...' % (os.path.getsize(filename) / 2.**20))\n",
        "        request.urlretrieve(url=url, filename=filename)\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    os.mkdir(data_path)\n",
        "\n",
        "print('\\n%d classes:' % len(classes))\n",
        "\n",
        "for name in classes:\n",
        "    print(name, end=' ')\n",
        "    dst = '%s/%s.ndjson' % (data_path, name)\n",
        "    retrieve('quickdraw_dataset', 'full/simplified/%s.ndjson' % name, dst)\n",
        "    print('%.2f MB' % (os.path.getsize(dst) / 2.**20))\n",
        "\n",
        "print('\\nDONE :)')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "42 classes:\n",
            "bat 58.02 MB\n",
            "bird 65.86 MB\n",
            "butterfly 63.27 MB\n",
            "camel 54.31 MB\n",
            "cat 73.12 MB\n",
            "cow 91.94 MB\n",
            "crab 76.46 MB\n",
            "crocodile 57.19 MB\n",
            "dog 87.06 MB\n",
            "dolphin 46.29 MB\n",
            "duck 67.93 MB\n",
            "elephant 70.86 MB\n",
            "fish 48.59 MB\n",
            "frog 92.50 MB\n",
            "giraffe 58.27 MB\n",
            "hedgehog 90.76 MB\n",
            "horse 99.79 MB\n",
            "kangaroo 96.06 MB\n",
            "lion 90.47 MB\n",
            "lobster 86.65 MB\n",
            "monkey 91.05 MB\n",
            "mosquito 64.99 MB\n",
            "mouse 76.35 MB\n",
            "octopus 79.30 MB\n",
            "owl 108.10 MB\n",
            "panda 97.04 MB\n",
            "parrot 96.42 MB\n",
            "penguin 137.90 MB\n",
            "pig 124.13 MB\n",
            "rabbit 95.05 MB\n",
            "raccoon 89.36 MB\n",
            "rhinoceros 92.20 MB\n",
            "scorpion 104.07 MB\n",
            "shark 48.55 MB\n",
            "sheep 80.55 MB\n",
            "snail 69.58 MB\n",
            "spider 115.32 MB\n",
            "squirrel 100.65 MB\n",
            "teddy-bear 128.27 MB\n",
            "tiger 86.09 MB\n",
            "whale 53.94 MB\n",
            "zebra 92.10 MB\n",
            "\n",
            "DONE :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KNvbLv_DrJEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inspect the data"
      ]
    },
    {
      "metadata": {
        "id": "Uo1nriHHpAx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's check out the downloaded files...\n",
        "# !ls -lh $data_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJvhPmhUpA00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What is the NDJSON file format?\n",
        "# Seems to be one JSON dictionary per line...\n",
        "# path = sorted(tf.gfile.Glob(os.path.join(data_path, '*.ndjson')))[1]\n",
        "# print(open(path).read()[:1000] + '...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZAjH8C_ErcfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Parse single line.\n",
        "# data_json = json.loads(open(path).readline())\n",
        "# data_json.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z6rlyutopA4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # ...and the actual drawing.\n",
        "# drawing = data_json['drawing']\n",
        "# # The drawing consists of a series of strokes:\n",
        "# [np.array(stroke).shape for stroke in drawing]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TMreYutksAB5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Draw the image -- the strokes all have have shape (2, n)\n",
        "# so the first index seems to be x/y coordinate:\n",
        "\n",
        "def draw_strokes(drawing):\n",
        "  # Use a different color for each stroke\n",
        "  colors = cm.rainbow(np.linspace(0, 1, len(drawing)))\n",
        "  plt.axis('off')\n",
        "  for stroke, c in zip(drawing, colors):\n",
        "    #print(stroke[0], stroke[1])\n",
        "    plt.plot(np.array(stroke[0]), -1 * np.array(stroke[1]), color=c)\n",
        "    \n",
        "# draw_strokes(drawing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "adZ2csaTsB7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Some more code to load many sketches at once.\n",
        "# Let's ignore the difficult \"unrecognized\" sketches for now...\n",
        "# (i.e. unrecognized by the official quickdraw classifier)\n",
        "\n",
        "def convert(line):\n",
        "    \"\"\"Converts single line to JSON + converts 'drawing' to list of np.array.\"\"\"\n",
        "    d = json.loads(line)\n",
        "    d['drawing'] = [np.array(stroke) for stroke in d['drawing']]\n",
        "    return d\n",
        "\n",
        "def loaditer(name, unrecognized=False):\n",
        "    \"\"\"Returns iterable of drawings in specified file.\n",
        "\n",
        "    Args:\n",
        "      name: Name of the downloaded object (e.g. \"elephant\").\n",
        "      unrecognized: Whether to include drawings that were not recognized\n",
        "          by Google AI (i.e. the hard ones).\n",
        "    \"\"\"\n",
        "    for line in open('%s/%s.ndjson' % (data_path, name)):\n",
        "        d = convert(line)\n",
        "        if d['recognized'] or unrecognized:\n",
        "            yield d\n",
        "\n",
        "def loadn(name, n, unrecognized=False):\n",
        "    \"\"\"Returns list of drawings.\n",
        "\n",
        "    Args:\n",
        "      name: Name of the downloaded object (e.g. \"elephant\").\n",
        "      n: Number of drawings to load.\n",
        "      unrecognized: Whether to include drawings that were not recognized\n",
        "          by Google AI (i.e. the hard ones).\n",
        "    \"\"\"\n",
        "    it = loaditer(name, unrecognized=unrecognized)\n",
        "    return list(itertools.islice(it, 0, n))\n",
        "\n",
        "# print('loading some \"%s\"...' % classes[0])\n",
        "# sample = loadn(classes[0], 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3VHjRztgsB-Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sample[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lQqGT5RrsCCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Some more drawings...\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# n = 3\n",
        "# for x in range(n):\n",
        "#     for y in range(n):\n",
        "#         i = x * n + y\n",
        "#         plt.subplot(n, n, i + 1)\n",
        "#         drawing = sample[i]['drawing']\n",
        "#         draw_strokes(drawing)\n",
        "        \n",
        "# # bats!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vgbObLbsCFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "41c94638-7f20-4aa7-f560-25f9f217e39a"
      },
      "cell_type": "code",
      "source": [
        "# Let's first check how many [recognized=True] examples we have in each class.\n",
        "# Depending on your choice of classes you could generate >200k examples / class...\n",
        "for name in classes:\n",
        "    print(name, len(list(open('%s/%s.ndjson' % (data_path, name)))), 'recognized', len(list(loaditer(name))))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bat 118114 recognized 96152\n",
            "bird 133572 recognized 111611\n",
            "butterfly 117999 recognized 114549\n",
            "camel 121399 recognized 115454\n",
            "cat 123202 recognized 103031\n",
            "cow 123083 recognized 101099\n",
            "crab 126930 recognized 106466\n",
            "crocodile 127932 recognized 106410\n",
            "dog 152159 recognized 143285\n",
            "dolphin 121613 recognized 110335\n",
            "duck 135480 recognized 113764\n",
            "elephant 126969 recognized 104986\n",
            "fish 134150 recognized 126420\n",
            "frog 159047 recognized 145286\n",
            "giraffe 127182 recognized 122396\n",
            "hedgehog 120527 recognized 103226\n",
            "horse 178286 recognized 156302\n",
            "kangaroo 174470 recognized 152511\n",
            "lion 120949 recognized 98976\n",
            "lobster 140175 recognized 118228\n",
            "monkey 127633 recognized 105650\n",
            "mosquito 123029 recognized 116609\n",
            "mouse 178826 recognized 166197\n",
            "octopus 150152 recognized 143558\n",
            "owl 169632 recognized 147654\n",
            "panda 113613 recognized 94814\n",
            "parrot 185530 recognized 163567\n",
            "penguin 253791 recognized 231826\n",
            "pig 186770 recognized 164788\n",
            "rabbit 155288 recognized 133323\n",
            "raccoon 119588 recognized 101174\n",
            "rhinoceros 188484 recognized 166539\n",
            "scorpion 165689 recognized 143724\n",
            "shark 126050 recognized 119434\n",
            "sheep 126121 recognized 117555\n",
            "snail 133757 recognized 128512\n",
            "spider 209447 recognized 187865\n",
            "squirrel 156883 recognized 134923\n",
            "teddy-bear 179568 recognized 157583\n",
            "tiger 121067 recognized 110177\n",
            "whale 116502 recognized 109081\n",
            "zebra 144608 recognized 127159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hY-CZS-VwC3P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make images from the brush stroke\n",
        "Convert sequences of strokes to images"
      ]
    },
    {
      "metadata": {
        "id": "e1yrBBKxwFs_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def json_to_img(drawing, img_sz=64, lw=3, maximize=True):\n",
        "    img = Image.new('L', (img_sz, img_sz))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    lines = np.array([\n",
        "        stroke[0:2, i:i+2]\n",
        "        for stroke in drawing\n",
        "        for i in range(stroke.shape[1] - 1)\n",
        "    ], dtype=np.float32)\n",
        "    if maximize:\n",
        "        for i in range(2):\n",
        "            min_, max_ = lines[:,i,:].min() * 0.95, lines[:,i,:].max() * 1.05\n",
        "            lines[:,i,:] = (lines[:,i,:] - min_) / max(max_ - min_, 1)\n",
        "    else:\n",
        "        lines /= 1024\n",
        "    for line in lines:\n",
        "        draw.line(tuple(line.T.reshape((-1,)) * img_sz), fill='white', width=lw)\n",
        "    return img\n",
        "  \n",
        "\n",
        "#json_to_img(drawing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I6k-Hb2dwFwp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fetch some images + shuffle order.\n",
        "n_per_class = 1000 #original 10000, but VGG16 fail to load such many features.\n",
        "drawings_matrix = [loadn(name, n_per_class) for name in classes]\n",
        "drawings_list = functools.reduce(lambda x, y: x + y, drawings_matrix, [])\n",
        "np.random.seed(1)\n",
        "drawings_list = np.random.permutation(drawings_list)\n",
        "\n",
        "# Quick test to see how our code works so far\n",
        "# draw_strokes(drawings_list[0]['drawing'])\n",
        "# print(str(drawings_list[0]['word']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jE_drPvRwF0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#json_to_img(drawings_list[0]['drawing'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_ome2yEw0Hw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the images to disk"
      ]
    },
    {
      "metadata": {
        "id": "2iZtvmDyw3tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e67eb1b-eaca-47e1-c82b-5b0a274a6a50"
      },
      "cell_type": "code",
      "source": [
        "np.shape(drawings_list)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "81HwwxXcwF3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save a dataset to disk\n",
        "X, y = [], []\n",
        "for drawing in drawings_list:\n",
        "  X.append(np.array(json_to_img(drawing['drawing'])))\n",
        "  y.append(str(drawing['word']))\n",
        "  \n",
        "dataset_path = 'mini-quickdraw.npz'\n",
        "out = open(dataset_path, 'wb') #must open as binary files, or error in python3\n",
        "# This may take a moment...\n",
        "np.savez_compressed(out, X, y, X=X, y=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SKRHtd72fUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp /content/mini-quickdraw.npz /content/gdrive/My\\ Drive/EC_ADL/mini-quickdraw-42animals.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lttE-wDXxgYX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 2. Classify with CNN\n",
        "Use transfer learning from VGG"
      ]
    },
    {
      "metadata": {
        "id": "tFA33bnfrx1F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load pics from Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "9K_rWgZM0utA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4fe66f4c-3616-4f44-8dcb-864324fdc10a"
      },
      "cell_type": "code",
      "source": [
        "# save the dataset to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eYmHQTY8wF6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "10405ea5-c1f1-4dba-dc5e-dd854082ba47"
      },
      "cell_type": "code",
      "source": [
        "# Demonstrate loading it back\n",
        "dataset_path = '/content/gdrive/My Drive/EC_ADL/mini-quickdraw-42animals.npz'\n",
        "loaded = np.load(open(dataset_path,'rb'))\n",
        "X, y = loaded[\"X\"], loaded[\"y\"]\n",
        "print(X.shape, y.shape)\n",
        "# it worked!\n",
        "plt.imshow(X[0])\n",
        "print(\"Label\", y[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 64, 64) (42000,)\n",
            "Label rabbit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nswT9HzWYNNm/CfjTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9MdoApVVyo6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sample 1000 images for each category and put into directory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1PmHGkwsTa6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing image data"
      ]
    },
    {
      "metadata": {
        "id": "tAXTDpFx1XXT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split images into directories labeled with class"
      ]
    },
    {
      "metadata": {
        "id": "5tbbbi7s1vLi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.mkdir('train')\n",
        "os.mkdir('val')\n",
        "for i in animals:\n",
        "  os.mkdir('train/'+i)\n",
        "  os.mkdir('val/'+i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUqJQLLA1vTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "504b7d96-58cd-4808-f56d-063037c2690d"
      },
      "cell_type": "code",
      "source": [
        "a = json_to_img(drawings_list[0]['drawing'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-004eca3d2bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrawings_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drawing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'json_to_img' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ek3aYkv51vRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pQ4sY3s1vO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5pPQjM9xCep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "532jAa9t1YWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "845252ae-5887-4dbd-a74d-94db8af4885d"
      },
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['rabbit', 'bat', 'spider', 'horse', 'giraffe'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2hxRlojMsfm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85db74bc-03e4-4c8d-ab6f-7f63a8bbbb5d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
        "print(np.shape(X_train), np.shape(y_test))\n",
        "print(y_train[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37800, 64, 64) (4200,)\n",
            "['octopus' 'raccoon' 'parrot' 'penguin' 'owl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MfVVCUw5wa03",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NCLASS = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uMSWsoI9sW_L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use VGG16"
      ]
    },
    {
      "metadata": {
        "id": "eogz06JOxCIJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(150, 150, 3))\n",
        "#conv_base.summary()\n",
        "\n",
        "TARGET_SHAPE = 150\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "def extract_features(x_data, y_data, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))#from block5 of VGG16\n",
        "    labels = np.zeros(shape=(sample_count, NCLASS))\n",
        "    generator = datagen.flow(\n",
        "        x_data,\n",
        "        y_data,\n",
        "        batch_size=BATCH_SIZE)\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "      \n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        \n",
        "        features[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = features_batch\n",
        "        labels[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = labels_batch\n",
        "        i += 1\n",
        "        if i * BATCH_SIZE >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(X_train, y_train, 37800)\n",
        "validation_features, validation_labels = extract_features(X_test,y_test, 4200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-vht_ZTyQ9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fD-zqgnFyF3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FLATTENED_SHAPE = 4 * 4 * 512\n",
        "\n",
        "train_features = np.reshape(train_features, (total_train, FLATTENED_SHAPE))\n",
        "validation_features = np.reshape(validation_features, (total_val, FLATTENED_SHAPE))\n",
        "EPOCHS = 50\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=FLATTENED_SHAPE))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NCLASS, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNiVcE434hxd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## test MobileNetV2"
      ]
    },
    {
      "metadata": {
        "id": "LrwyxXn_yF64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "conv_base4 = MobileNetV2(weights='imagenet',include_top=False, input_shape=(128,128, 3))\n",
        "#conv_base4.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0awD0zeKyF-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "72acd34e-fe18-4878-8337-9e0fc1cdfdd5"
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "TARGET_SHAPE = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def extract_features(x_data, y_data, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 1280))#from ResNet\n",
        "    labels = np.zeros(shape=(sample_count, NCLASS))\n",
        "    generator = datagen.flow(\n",
        "        x_data,\n",
        "        y_data,\n",
        "        batch_size=BATCH_SIZE)\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "      \n",
        "        features_batch = conv_base4.predict(inputs_batch)\n",
        "        \n",
        "        features[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = features_batch\n",
        "        labels[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = labels_batch\n",
        "        i += 1\n",
        "        if i * BATCH_SIZE >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(X_train, y_train, 37800)\n",
        "validation_features, validation_labels = extract_features(X_test, y_test, 4200)\n",
        "\n",
        "\n",
        "FLATTENED_SHAPE = 4 * 4 * 1280\n",
        "\n",
        "train_features = np.reshape(train_features, (total_train, FLATTENED_SHAPE))\n",
        "validation_features = np.reshape(validation_features, (total_val, FLATTENED_SHAPE))\n",
        "EPOCHS = 50\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=FLATTENED_SHAPE))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NCLASS, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history4 = model.fit(train_features, train_labels,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4636047f7573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mvalidation_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-4636047f7573>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(x_data, y_data, sample_count)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         batch_size=BATCH_SIZE)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    116\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (37800, 64, 64))"
          ]
        }
      ]
    }
  ]
}