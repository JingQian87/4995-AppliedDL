{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A4-jq2282.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q-DgS7Ocd4qQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 4 Real-time text classification in the browser\n",
        "### Jing Qian (jq2282)"
      ]
    },
    {
      "metadata": {
        "id": "WG9l9YJ3qYrn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1\n",
        "Modify the starter code (​7-colab-to-webpage.ipynb​) ​to classify snippets of text from four books on ​Project Gutenberg​. \n",
        "\n",
        "Given a snippet of text (not necessarily a complete sentence) predict which book it belongs to.\n"
      ]
    },
    {
      "metadata": {
        "id": "5kTVHyQxvDu6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. Environment Preparation"
      ]
    },
    {
      "metadata": {
        "id": "0FAw9Qa0akC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olI7l_bmcCMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs==1.0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNILWuVrvLJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Connet to the github page, use the applied-dl repository: https://github.com/fakeJQ/applied-dl. \n",
        "\n",
        "Generated page of the repository, shown as: https://fakejq.github.io/applied-dl/"
      ]
    },
    {
      "metadata": {
        "id": "8jnxQeiQxF3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. Copy repository from Github"
      ]
    },
    {
      "metadata": {
        "id": "007TFGrqeHq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"fakeJQ\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as is)\n",
        "USER_EMAIL = \"tcqj_8758@163.com\" \n",
        "\n",
        "# create a token by visiting https://github.com/settings/tokens\n",
        "# choose public permissions\n",
        "# important: treat this token like a password (do not commit it)\n",
        "# or submit it w/ your HW.\n",
        "TOKEN = \"89d35eaae4bb746d07f304526f39807c2c267f5c\" \n",
        "\n",
        "# for example, if your user_name is \"foo\", then this notebook will create\n",
        "# a site at \"https://foo.github.io/hw4/\"\n",
        "SITE_NAME = \"hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mAF4WYFDeSqj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ykgeRmHeYRR",
        "colab_type": "code",
        "outputId": "e0a93a1e-897d-444c-9d1d-9e51df248aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = USER_NAME + '.github.io'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/applied-dl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'applied-dl' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7oDw9vhZihwK",
        "colab_type": "code",
        "outputId": "8a2da844-8459-4e27-9d14-4f5e6fa3518b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/applied-dl')\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UQ3thYvLjwAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y33fXMHYjwD0",
        "colab_type": "code",
        "outputId": "af732027-db19-4d5d-9a7f-a5d7f4f9ce4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(project_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/applied-dl/hw4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DoRtckGSkVK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZSAGAlHbv7d0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3. Data preparation \n",
        "\n",
        "Using method from https://www.nltk.org/book/ch02.html"
      ]
    },
    {
      "metadata": {
        "id": "OPfR1-rdJY5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "gutenberg.fileids ()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tAhZYg4jk45m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test with words form, not use it.\n",
        "emma_words = gutenberg.words('austen-emma.txt')\n",
        "len(emma_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CpyZlsvJlMeY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import books in forms of sentences\n",
        "nltk.download('punkt')\n",
        "emma = gutenberg.sents('austen-emma.txt')\n",
        "paradise = gutenberg.sents('milton-paradise.txt')\n",
        "hamlet = gutenberg.sents('shakespeare-hamlet.txt')\n",
        "leaves = gutenberg.sents('whitman-leaves.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3uDysJPmEVh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "nlines = 3 # later to 1000, as required\n",
        "emma_pick = np.random.choice(emma, nlines)\n",
        "paradise_pick = np.random.choice(paradise, nlines)\n",
        "hamlet_pick = np.random.choice(hamlet, nlines)\n",
        "leaves_pick = np.random.choice(leaves, nlines)\n",
        "x_train = np.vstack((emma_pick, paradise_pick, hamlet_pick, leaves_pick))\n",
        "x_train = x_train.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bh5IsYMnriUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6428007e-1117-40d4-bb89-a163bcbcbf5b"
      },
      "cell_type": "code",
      "source": [
        "#label 0:emma, label 1:paradise, 2:hamlet, 3:leaves\n",
        "y_train = [0]*nlines + [1]*nlines + [2]*nlines + [3]*nlines"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "Ha3q3HcHkjNX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 1000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mm8mmJkSklev",
        "colab_type": "code",
        "outputId": "d650a99c-7227-43fa-a971-bf4a9fac55c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(t.word_index)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{',': 1, 'the': 2, '.': 3, 'to': 4, 'i': 5, 'and': 6, 'or': 7, 'with': 8, 'you': 9, 'that': 10, 'have': 11, 'of': 12, 'for': 13, ';': 14, 'from': 15, \"'\": 16, 'so': 17, 'much': 18, 'in': 19, 'praise': 20, 'at': 21, 'time': 22, 'it': 23, 'themselves': 24, 'by': 25, 'no': 26, 'be': 27, 'rise': 28, 'great': 29, 'falling': 30, 'whom': 31, 'nor': 32, 'd': 33, '?': 34, 'see': 35, 'heard': 36, 'mr': 37, 'frank': 38, 'churchill': 39, '.--': 40, 'same': 41, 'is': 42, 'fair': 43, 'observe': 44, 'am': 45, 'one': 46, 'those': 47, 'who': 48, 'always': 49, 'judge': 50, 'are': 51, 'means': 52, 'implicitly': 53, 'guided': 54, 'others': 55, 'emma': 56, 'found': 57, 'really': 58, 'home': 59, 'visit': 60, 'had': 61, 'already': 62, 'lasted': 63, 'long': 64, 'on': 65, 'examining': 66, 'watches': 67, 'morning': 68, 'was': 69, 'perceived': 70, 'gone': 71, 'mrs': 72, 'weston': 73, 'her': 74, 'companion': 75, 'taking': 76, 'leave': 77, 'also': 78, 'could': 79, 'allow': 80, 'only': 81, 'walk': 82, 'two': 83, 'young': 84, 'ladies': 85, 'hartfield': 86, 'gates': 87, 'before': 88, 'they': 89, 'set': 90, 'off': 91, 'randalls': 92, 'assure': 93, 'ye': 94, 'mists': 95, 'exhalations': 96, 'now': 97, 'hill': 98, 'steaming': 99, 'lake': 100, 'dusky': 101, 'gray': 102, 'till': 103, 'sun': 104, 'paint': 105, 'your': 106, 'fleecy': 107, 'skirts': 108, 'gold': 109, 'honour': 110, 'world': 111, 's': 112, 'author': 113, 'whether': 114, 'deck': 115, 'clouds': 116, 'uncoloured': 117, 'sky': 118, 'wet': 119, 'thirsty': 120, 'earth': 121, 'showers': 122, 'rising': 123, 'still': 124, 'advance': 125, 'his': 126, 'creator': 127, 'thus': 128, 'replied': 129, 'will': 130, 'occasion': 131, 'want': 132, 'shall': 133, 'we': 134, 'need': 135, 'dangerous': 136, 'expedition': 137, 'invade': 138, 'heaven': 139, 'whose': 140, 'high': 141, 'walls': 142, 'fear': 143, 'assault': 144, 'siege': 145, 'ambush': 146, 'deep': 147, 'king': 148, 'ham': 149, '(': 150, 'slaughter': 151, 'lately': 152, 'european': 153, 'headsman': 154, 'were': 155, 'as': 156, 'boss': 157, 'employing': 158, 'paying': 159, 'would': 160, 'satisfy': 161, '10': 162, 'vapors': 163, 'exhaling': 164, 'unexplored': 165, 'countries': 166, 'savage': 167, 'types': 168, 'bow': 169, 'arrow': 170, 'poison': 171, 'splint': 172, 'fetich': 173, 'obi': 174}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd7NSkrNklig",
        "colab_type": "code",
        "outputId": "4290961d-6803-44f4-db1f-0f04c560f9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences(emma_pick)\n",
        "print(vectorized)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5, 11, 36, 17, 18, 19, 20, 12, 37, 3, 38, 39, 40, 21, 2, 41, 22, 23, 42, 43, 4, 44, 1, 10, 5, 45, 46, 12, 47, 48, 49, 50, 13, 24, 1, 6, 51, 25, 26, 52, 53, 54, 25, 55, 3], [56, 57, 23, 58, 22, 4, 27, 21, 59, 14, 2, 60, 61, 62, 63, 64, 14, 6, 65, 66, 67, 1, 17, 18, 12, 2, 68, 69, 70, 4, 27, 71, 1, 10, 72, 3, 73, 6, 74, 75, 76, 77, 78, 1, 79, 80, 24, 81, 4, 82, 8, 2, 83, 84, 85, 4, 86, 87, 1, 88, 89, 90, 91, 13, 92, 3], [5, 93, 9, 5, 11, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dzYVp46fklmW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4VODjdIksry",
        "colab_type": "code",
        "outputId": "c85730a1-578b-4d21-86af-c203672b1ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[45 46 12 47 48 49 50 13 24  1  6 51 25 26 52 53 54 25 55  3]\n",
            " [24 81  4 82  8  2 83 84 85  4 86 87  1 88 89 90 91 13 92  3]\n",
            " [ 5 93  9  5 11  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lT_V6GZmksvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtTJGE_QxX27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. Define a model, train and test"
      ]
    },
    {
      "metadata": {
        "id": "NLSxcbnWkszT",
        "colab_type": "code",
        "outputId": "cc2bb832-3dc0-41a0-eff8-378e8a92472a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 8\n",
        "n_classes = 4\n",
        "epochs = 10\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 8)             8000      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 644       \n",
            "=================================================================\n",
            "Total params: 8,644\n",
            "Trainable params: 8,644\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "THlLzuLFks2m",
        "colab_type": "code",
        "outputId": "8ed776a1-1070-4f71-b0c6-ceb5ed53e037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 45  46  12  47  48  49  50  13  24   1   6  51  25  26  52  53  54  25\n",
            "   55   3]\n",
            " [ 24  81   4  82   8   2  83  84  85   4  86  87   1  88  89  90  91  13\n",
            "   92   3]\n",
            " [  5  93   9   5  11   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [117 118   1   7 119   2 120 121   8  30 122   1 123   7  30 124 125 126\n",
            "   20   3]\n",
            " [  4  31   2  29 127 128 129   3   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [137   4 138 139   1 140 141 142 143  26 144   7 145   1   7 146  15   2\n",
            "  147   3]\n",
            " [ 13   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [148   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [149   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [150  31  11   9 151  16  33 152 153 154  34   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [155   5   4   9 156   2 157 158   6 159   9   1 160  10 161   9  34   0\n",
            "    0   0]\n",
            " [168   1   2 169   6 170   1   2 171  16  33 172   1   2 173   1   6   2\n",
            "  174   3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qaxPLGFvks6s",
        "colab_type": "code",
        "outputId": "844cb057-feb9-4332-d781-605b00ae6052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=epochs)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 0s 34ms/sample - loss: 1.3836 - acc: 0.1667\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 484us/sample - loss: 1.3760 - acc: 0.1667\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 235us/sample - loss: 1.3685 - acc: 0.3333\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 220us/sample - loss: 1.3609 - acc: 0.3333\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 217us/sample - loss: 1.3534 - acc: 0.4167\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 292us/sample - loss: 1.3458 - acc: 0.4167\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 356us/sample - loss: 1.3382 - acc: 0.6667\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 179us/sample - loss: 1.3306 - acc: 0.6667\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 154us/sample - loss: 1.3229 - acc: 0.6667\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 169us/sample - loss: 1.3153 - acc: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e8025dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "fye5x8hTk28t",
        "colab_type": "code",
        "outputId": "b4264afa-e978-4bdf-a3db-fbe8d8e1beac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "test_example = paradise[1200]\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "print(x_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 81   1   1   8 126  12 126  26  65   1  65  14   7  25  34   0   0   0\n",
            "    0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UYoMPP8Vks-N",
        "colab_type": "code",
        "outputId": "911cab54-0a8d-4d09-9e64-7e7caed21d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "import numpy as np\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.24311227 0.26148778 0.24880302 0.24659693]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "katbomi_xkZK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. Goto html!"
      ]
    },
    {
      "metadata": {
        "id": "JUfiXSXkk8cA",
        "colab_type": "code",
        "outputId": "a37df651-0841-4c59-b25c-87164e134663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model artifcats in directory: /content/applied-dl/hw4/model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RAIBwRjzk8fQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
        "      <option value=\"example2\">Dracula</option>\n",
        "      <option value=\"example3\">The Iliad</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ut7T6FdQk8kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
        "  'example2':\n",
        "      'Buda-Pesth seems a wonderful place.',\n",
        "  'example3':\n",
        "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadLayersModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycCV-t1Fk8n9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdDhUwQ5k8rF",
        "colab_type": "code",
        "outputId": "96f93463-6877-42d2-809f-179334f64e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index.html  index.js  model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yQeTiua_k8ua",
        "colab_type": "code",
        "outputId": "c3649d9e-b6a1-49a2-a61f-dd25797276cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "#!git add . \n",
        "#!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/applied-dl.git master\n",
        "#!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/applied-dl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 9, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  11% (1/9)   \rCompressing objects:  22% (2/9)   \rCompressing objects:  33% (3/9)   \rCompressing objects:  44% (4/9)   \rCompressing objects:  55% (5/9)   \rCompressing objects:  66% (6/9)   \rCompressing objects:  77% (7/9)   \rCompressing objects:  88% (8/9)   \rCompressing objects: 100% (9/9)   \rCompressing objects: 100% (9/9), done.\n",
            "Writing objects:  11% (1/9)   \rWriting objects:  22% (2/9)   \rWriting objects:  33% (3/9)   \rWriting objects:  44% (4/9)   \rWriting objects:  55% (5/9)   \rWriting objects:  66% (6/9)   \rWriting objects:  77% (7/9)   \rWriting objects:  88% (8/9)   \rWriting objects: 100% (9/9)   \rWriting objects: 100% (9/9), 34.15 KiB | 11.38 MiB/s, done.\n",
            "Total 9 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/fakeJQ/applied-dl.git\n",
            "   f116369..0804b74  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2QuvjTM-k8iG",
        "colab_type": "code",
        "outputId": "0fa432a8-6ccb-46e8-f4ce-1bc6c235a0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/applied-dl/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://fakeJQ.github.io/applied-dl/hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}