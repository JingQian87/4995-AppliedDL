{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A4-jq2282.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q-DgS7Ocd4qQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 4 Real-time text classification in the browser\n",
        "### Jing Qian (jq2282)"
      ]
    },
    {
      "metadata": {
        "id": "WG9l9YJ3qYrn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1"
      ]
    },
    {
      "metadata": {
        "id": "5kTVHyQxvDu6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1. Environment Preparation"
      ]
    },
    {
      "metadata": {
        "id": "0FAw9Qa0akC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olI7l_bmcCMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs==1.0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNILWuVrvLJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Connet to the github page, use the applied-dl repository: https://github.com/fakeJQ/applied-dl. \n",
        "\n",
        "Generated page of the repository, shown as: https://fakejq.github.io/applied-dl/"
      ]
    },
    {
      "metadata": {
        "id": "8jnxQeiQxF3C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2. Copy repository from Github"
      ]
    },
    {
      "metadata": {
        "id": "007TFGrqeHq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"fakeJQ\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as is)\n",
        "USER_EMAIL = \"tcqj_8758@163.com\" \n",
        "\n",
        "# create a token by visiting https://github.com/settings/tokens\n",
        "# choose public permissions\n",
        "# important: treat this token like a password (do not commit it)\n",
        "# or submit it w/ your HW.\n",
        "TOKEN = \"89d35eaae4bb746d07f304526f39807c2c267f5c\" \n",
        "\n",
        "# for example, if your user_name is \"foo\", then this notebook will create\n",
        "# a site at \"https://foo.github.io/hw4/\"\n",
        "SITE_NAME = \"hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mAF4WYFDeSqj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ykgeRmHeYRR",
        "colab_type": "code",
        "outputId": "e0a93a1e-897d-444c-9d1d-9e51df248aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = USER_NAME + '.github.io'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/applied-dl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'applied-dl' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7oDw9vhZihwK",
        "colab_type": "code",
        "outputId": "8a2da844-8459-4e27-9d14-4f5e6fa3518b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/applied-dl')\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UQ3thYvLjwAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y33fXMHYjwD0",
        "colab_type": "code",
        "outputId": "af732027-db19-4d5d-9a7f-a5d7f4f9ce4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(project_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/applied-dl/hw4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSAGAlHbv7d0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 3. Data preparation "
      ]
    },
    {
      "metadata": {
        "id": "DoRtckGSkVK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ZT037vmiqxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A few sentences from Alice in Wonderland\n",
        "ex1 = \"Alice was beginning to get very tired of sitting by her sister on the bank.\"\n",
        "ex2 = \"Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it.\"\n",
        "\n",
        "# Dracula\n",
        "ex3 = \"Buda-Pesth seems a wonderful place.\"\n",
        "ex4 = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "\n",
        "# Illiad\n",
        "ex5 = \"Scepticism was as much the result of knowledge, as knowledge is of scepticism.\"\n",
        "ex6 = \"To be content with what we at present know, is, for the most part, to shut our ears against conviction.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rl4Rso_-kfdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = [ex1, ex2, ex3, ex4, ex5, ex6]\n",
        "y_train = [0, 0, 1, 1, 2, 2] # Indicating which book each sentence is from"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ha3q3HcHkjNX",
        "colab_type": "code",
        "outputId": "95ba6f21-f6f9-4899-b440-979d53132311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 1000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mm8mmJkSklev",
        "colab_type": "code",
        "outputId": "85871528-d8b7-4a0c-fb51-5cf5ac138973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(t.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'was': 2, 'to': 3, 'of': 4, 'at': 5, 'her': 6, 'sister': 7, 'on': 8, 'or': 9, 'had': 10, 'it': 11, 'scepticism': 12, 'as': 13, 'knowledge': 14, 'is': 15, 'alice': 16, 'beginning': 17, 'get': 18, 'very': 19, 'tired': 20, 'sitting': 21, 'by': 22, 'bank': 23, 'once': 24, 'twice': 25, 'she': 26, 'peeped': 27, 'into': 28, 'book': 29, 'reading': 30, 'but': 31, 'no': 32, 'pictures': 33, 'conversations': 34, 'in': 35, 'buda': 36, 'pesth': 37, 'seems': 38, 'a': 39, 'wonderful': 40, 'place': 41, 'left': 42, 'munich': 43, '8': 44, '35': 45, 'p': 46, 'm': 47, '1st': 48, 'may': 49, 'arriving': 50, 'vienna': 51, 'early': 52, 'next': 53, 'morning': 54, 'much': 55, 'result': 56, 'be': 57, 'content': 58, 'with': 59, 'what': 60, 'we': 61, 'present': 62, 'know': 63, 'for': 64, 'most': 65, 'part': 66, 'shut': 67, 'our': 68, 'ears': 69, 'against': 70, 'conviction': 71}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bd7NSkrNklig",
        "colab_type": "code",
        "outputId": "5124ea39-c04c-4432-991c-b8437b61f279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences([ex1])\n",
        "print(vectorized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16, 2, 17, 3, 18, 19, 20, 4, 21, 22, 6, 7, 8, 1, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dzYVp46fklmW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4VODjdIksry",
        "colab_type": "code",
        "outputId": "f35349d0-e177-4469-9461-32df108ec0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  2 17  3 18 19 20  4 21 22  6  7  8  1 23  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lT_V6GZmksvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtTJGE_QxX27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 4. Define a model, train and test"
      ]
    },
    {
      "metadata": {
        "id": "NLSxcbnWkszT",
        "colab_type": "code",
        "outputId": "a3d36df8-e32d-4d09-a5e9-b4af7c7db223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "embedding_size = 8\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 8)             8000      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 483       \n",
            "=================================================================\n",
            "Total params: 8,483\n",
            "Trainable params: 8,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "THlLzuLFks2m",
        "colab_type": "code",
        "outputId": "70fa7c85-9031-479b-bc37-154a43113807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  2 17  3 18 19 20  4 21 22  6  7  8  1 23  0  0  0  0  0]\n",
            " [25 26 10 27 28  1 29  6  7  2 30 31 11 10 32 33  9 34 35 11]\n",
            " [36 37 38 39 40 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 43  5 44 45 46 47  8 48 49 50  5 51 52 53 54  0  0  0  0]\n",
            " [12  2 13 55  1 56  4 14 13 14 15  4 12  0  0  0  0  0  0  0]\n",
            " [ 3 57 58 59 60 61  5 62 63 15 64  1 65 66  3 67 68 69 70 71]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qaxPLGFvks6s",
        "colab_type": "code",
        "outputId": "5401aa8e-2b7b-4d5a-e200-4651da455c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(x_train, y_train, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 21ms/sample - loss: 1.0910 - accuracy: 0.1667\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 725us/sample - loss: 1.0814 - accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 416us/sample - loss: 1.0719 - accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 386us/sample - loss: 1.0623 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 381us/sample - loss: 1.0528 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 460us/sample - loss: 1.0433 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 414us/sample - loss: 1.0338 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 412us/sample - loss: 1.0243 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 599us/sample - loss: 1.0148 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 313us/sample - loss: 1.0053 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba4519df60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "fye5x8hTk28t",
        "colab_type": "code",
        "outputId": "2ec90c66-8373-4a6c-a91e-6073c05f0359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[42 43  5 44 45 46 47  8 48 49 50  5 51 52 53 54  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UYoMPP8Vks-N",
        "colab_type": "code",
        "outputId": "b14aba9d-f6d8-4928-81ce-5394791e5e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "import numpy as np\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.30840474 0.3829351  0.30866015]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "katbomi_xkZK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 5. Goto html!"
      ]
    },
    {
      "metadata": {
        "id": "JUfiXSXkk8cA",
        "colab_type": "code",
        "outputId": "a37df651-0841-4c59-b25c-87164e134663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model artifcats in directory: /content/applied-dl/hw4/model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RAIBwRjzk8fQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
        "      <option value=\"example2\">Dracula</option>\n",
        "      <option value=\"example3\">The Iliad</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ut7T6FdQk8kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
        "  'example2':\n",
        "      'Buda-Pesth seems a wonderful place.',\n",
        "  'example3':\n",
        "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadLayersModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycCV-t1Fk8n9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdDhUwQ5k8rF",
        "colab_type": "code",
        "outputId": "96f93463-6877-42d2-809f-179334f64e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index.html  index.js  model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yQeTiua_k8ua",
        "colab_type": "code",
        "outputId": "c3649d9e-b6a1-49a2-a61f-dd25797276cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "#!git add . \n",
        "#!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/applied-dl.git master\n",
        "#!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/applied-dl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 9, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  11% (1/9)   \rCompressing objects:  22% (2/9)   \rCompressing objects:  33% (3/9)   \rCompressing objects:  44% (4/9)   \rCompressing objects:  55% (5/9)   \rCompressing objects:  66% (6/9)   \rCompressing objects:  77% (7/9)   \rCompressing objects:  88% (8/9)   \rCompressing objects: 100% (9/9)   \rCompressing objects: 100% (9/9), done.\n",
            "Writing objects:  11% (1/9)   \rWriting objects:  22% (2/9)   \rWriting objects:  33% (3/9)   \rWriting objects:  44% (4/9)   \rWriting objects:  55% (5/9)   \rWriting objects:  66% (6/9)   \rWriting objects:  77% (7/9)   \rWriting objects:  88% (8/9)   \rWriting objects: 100% (9/9)   \rWriting objects: 100% (9/9), 34.15 KiB | 11.38 MiB/s, done.\n",
            "Total 9 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/fakeJQ/applied-dl.git\n",
            "   f116369..0804b74  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2QuvjTM-k8iG",
        "colab_type": "code",
        "outputId": "0fa432a8-6ccb-46e8-f4ce-1bc6c235a0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/applied-dl/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://fakeJQ.github.io/applied-dl/hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}