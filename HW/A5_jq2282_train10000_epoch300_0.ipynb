{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A5_jq2282_train10000_epoch300_0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "uhk7LSRmH3H7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "faP_TfySH12q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 5 Machine Translation\n",
        "### Jing Qian (jq2282)"
      ]
    },
    {
      "metadata": {
        "id": "uhk7LSRmH3H7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1. Install packages and load libraries\n"
      ]
    },
    {
      "metadata": {
        "id": "TkZU21YuHt1Y",
        "colab_type": "code",
        "outputId": "bf7ca220-7bfa-49d0-beae-2fb33befe7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 332.1MB 62kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 8.5MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 29.3MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 419kB 11.2MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading https://files.pythonhosted.org/packages/12/5b/7196b11bca204cb6ca9000b5dc910e809081f224c73ef28e9991080e4e51/sacrebleu-1.3.1.tar.gz\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Building wheels for collected packages: sacrebleu\n",
            "  Building wheel for sacrebleu (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/56/c0/fb/1c7f9b3a71f64cdf86291cc645596f71746807bf2f72b3c1dd\n",
            "Successfully built sacrebleu\n",
            "Installing collected packages: sacrebleu\n",
            "Successfully installed sacrebleu-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bIPY-Wq6H0wK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXGdnexoH_5q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2. Load and preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "Tq8ETDnxJODV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1. Load and select data"
      ]
    },
    {
      "metadata": {
        "id": "2diHj7jsIFOj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ntrain = 10000\n",
        "ntest = 1000\n",
        "nall = ntrain + ntest\n",
        "nepoch = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7LoioJgIO97",
        "colab_type": "code",
        "outputId": "363318ba-8a70-42e4-e5e4-0a7edc98e98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SLRG0JchISlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load(fname):\n",
        "  # Load the file using std open\n",
        "  f = open(fname, 'r')\n",
        "  text = []\n",
        "  for line in f.readlines():\n",
        "    text.append(line.replace('\\n','').split('\\t'))\n",
        "    \n",
        "  f.close()\n",
        "  return text\n",
        "\n",
        "data = load('/content/gdrive/My Drive/spa-eng/spa.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sBcVdFi2IUaO",
        "colab_type": "code",
        "outputId": "18ede775-48a7-4f8e-d766-6c864ab07caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "print(data[10:15])\n",
        "print(np.shape(data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Fire!', '¡Disparad!'], ['Help!', '¡Ayuda!'], ['Help!', '¡Socorro! ¡Auxilio!'], ['Help!', '¡Auxilio!'], ['Jump!', '¡Salta!']]\n",
            "(118964, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mGNOKNclIYC-",
        "colab_type": "code",
        "outputId": "89bbafe2-eb6f-4aa1-ceae-04cfbde070a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#np.random.seed(10)\n",
        "shuffled_data = np.random.permutation(data)\n",
        "selected_id = np.random.randint(len(data), size = nall)\n",
        "train_data = shuffled_data[selected_id[:ntrain], :]\n",
        "print(np.shape(train_data), np.shape(shuffled_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2) (118964, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "skj36OdHJR-7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2. Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "Ndtl8GZZJUbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XeZOk_9qJktc",
        "colab_type": "code",
        "outputId": "c1432719-2f78-4065-ad5a-e97fa0a92986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = [(preprocess(eng), preprocess(spa)) for (eng, spa) in train_data]\n",
        "print(train_data[0])\n",
        "train_eng, train_spa = list(zip(*train_data))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('<start> I want to eat something delicious . <end>', '<start> Quiero comer algo delicioso . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8yTgCvxAKKEg",
        "colab_type": "code",
        "outputId": "a034d3b3-7a19-4cdf-8806-467036646fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "eng_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "eng_tokenizer.fit_on_texts(train_eng)\n",
        "train_eng = eng_tokenizer.texts_to_sequences(train_eng)\n",
        "train_eng = tf.keras.preprocessing.sequence.pad_sequences(train_eng, padding='post')\n",
        "print(train_eng[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1    4   35    6  131  106 1862    3    2    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5JpJftKK8gY",
        "colab_type": "code",
        "outputId": "aea0aff1-1f2a-43bc-dba3-f7bc3f600d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "spa_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "spa_tokenizer.fit_on_texts(train_spa)\n",
        "train_spa = spa_tokenizer.texts_to_sequences(train_spa)\n",
        "train_spa = tf.keras.preprocessing.sequence.pad_sequences(train_spa, padding='post')\n",
        "print(train_spa[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   44  142   56 2263    3    2    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rs323ojHMrM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "spa_vocab_size = len(spa_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h0jztFXOM6S1",
        "colab_type": "code",
        "outputId": "669dad84-43b2-4eab-ea66-59a9594cb360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "# Demonstrate the correspondence between word and code, not used in model\n",
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "decode(train_eng[0], eng_tokenizer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "4 -> i\n",
            "35 -> want\n",
            "6 -> to\n",
            "131 -> eat\n",
            "106 -> something\n",
            "1862 -> delicious\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WCfXlH0AIo6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3. Train Model 1: translate from English to Spanish\n"
      ]
    },
    {
      "metadata": {
        "id": "mq3UxYQzNNsg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1. Prepare data for model1"
      ]
    },
    {
      "metadata": {
        "id": "a0eLXu-NIoNK",
        "colab_type": "code",
        "outputId": "584c20be-f25d-4d03-a8f8-1755d8512624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(train_spa.shape)\n",
        "target_labels[:,0:train_spa.shape[1] -1] = train_spa[:,1:]\n",
        "\n",
        "print(\"Target sequence\", train_spa[0])\n",
        "print(\"Target label\", target_labels[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [   1   44  142   56 2263    3    2    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "Target label [4.400e+01 1.420e+02 5.600e+01 2.263e+03 3.000e+00 2.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qafjzAUJN-fN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_eng, train_spa, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QRBV9vaOJ_V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test code!\n",
        "# example_batch = next(iter(dataset))\n",
        "# source, target, taget_labels = example_batch\n",
        "# print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f95J-IkqQ6xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2. General components for models"
      ]
    },
    {
      "metadata": {
        "id": "yCs_-y6FOPZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "rnn_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrHuydEsOmPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Differ from example, add source_vocab_size to initialization\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, source_vocab_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqWK4AHTOvBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test code!\n",
        "# Create a batch of one sentence\n",
        "# ex_sentence = tf.expand_dims(train_eng[0], axis=0)\n",
        "# ex_translation = tf.expand_dims(train_spa[0], axis=0)\n",
        "# ex_labels = tf.expand_dims(target_labels[0], axis=0)\n",
        "# print(ex_sentence.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TECibZsPQokh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Differ from example, add target_vocab_size to initialization\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, target_vocab_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yo5xNFnJQyBw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "#print(\"Loss\", calc_loss(ex_labels, decoder_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUM198fKQyEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(idx=None, flag=1):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(train_data))\n",
        "    \n",
        "    if flag == 1:\n",
        "      source_data = train_eng\n",
        "      target_tokenizer = spa_tokenizer\n",
        "      encoder = encoder1\n",
        "      decoder = decoder1\n",
        "      tmp0, tmp1 = train_data[idx][0], train_data[idx][1]\n",
        "    elif flag == 2:\n",
        "      source_data = train_spa\n",
        "      target_tokenizer = eng_tokenizer\n",
        "      encoder = encoder2\n",
        "      decoder = decoder2\n",
        "      tmp0, tmp1 = train_data[idx][1], train_data[idx][0] \n",
        "    elif flag == 3:\n",
        "      source_data = test_eng\n",
        "      target_tokenizer = spa_tokenizer\n",
        "      encoder = encoder1\n",
        "      decoder = decoder1\n",
        "      tmp0, tmp1 = test_data[idx][0], test_data[idx][1]\n",
        "    elif flag == 4:\n",
        "      source_data = input_spa\n",
        "      target_tokenizer = eng_tokenizer\n",
        "      encoder = encoder2\n",
        "      decoder = decoder2\n",
        "      tmp0, tmp1 = middle_spa[idx], test_data[idx][0]       \n",
        "      \n",
        "    input_sent = source_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return tmp0, tmp1, translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7YSgbsvQyIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "# input_sent, target_sent, translation = translate()\n",
        "# print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spcI0A4HWRQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HXX5F79WUIy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3. Train Model 1: from English to Spanish"
      ]
    },
    {
      "metadata": {
        "id": "Np7vJsGQWcin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder1(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder1(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder1.trainable_variables + decoder1.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHm1Riq8YH-0",
        "colab_type": "code",
        "outputId": "470620d0-d923-42c0-b183-122e980af8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2587
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = nepoch\n",
        "\n",
        "encoder1 = Encoder(eng_vocab_size)\n",
        "decoder1 = Decoder(spa_vocab_size)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder1.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 0.6992, Time 17.20 sec\n",
            "Input: <start> He turned around and looked back . <end>\n",
            "Target: <start> El se volteo y miro hacia atras . <end>\n",
            "Translation: tom que no que no que que que que que que que que que que que que que que que\n",
            "\n",
            "Epoch #10, Loss 0.3488, Time 11.65 sec\n",
            "Input: <start> I thought he would come . <end>\n",
            "Target: <start> Yo pense que el vendria . <end>\n",
            "Translation: pense que tom es un buen profesor . <end>\n",
            "\n",
            "Epoch #20, Loss 0.2378, Time 11.59 sec\n",
            "Input: <start> I ll get you out of this horrible situation . <end>\n",
            "Target: <start> Te sacare de este horrible trance . <end>\n",
            "Translation: ojala tuviera mucho tiempo para hacer . <end>\n",
            "\n",
            "Epoch #30, Loss 0.1988, Time 11.63 sec\n",
            "Input: <start> It was extremely weird . <end>\n",
            "Target: <start> Fue muy raro . <end>\n",
            "Translation: fue a buscarle un hombre . <end>\n",
            "\n",
            "Epoch #40, Loss 0.1539, Time 11.58 sec\n",
            "Input: <start> That , of course , does not mean that they are right . <end>\n",
            "Target: <start> Por supuesto , eso no quiere decir que ellos tengan razon . <end>\n",
            "Translation: para gente por que se lo des a su primer , se derrite . <end>\n",
            "\n",
            "Epoch #50, Loss 0.1583, Time 11.58 sec\n",
            "Input: <start> Are you saying that I m a liar ? <end>\n",
            "Target: <start> ¿ Estais diciendo que soy una mentirosa ? <end>\n",
            "Translation: ¿ estas seguro de eso ? <end>\n",
            "\n",
            "Epoch #60, Loss 0.1294, Time 11.58 sec\n",
            "Input: <start> I don t like that woman . <end>\n",
            "Target: <start> No me gusta esa mujer . <end>\n",
            "Translation: no me gusta esa novia . <end>\n",
            "\n",
            "Epoch #70, Loss 0.0863, Time 11.62 sec\n",
            "Input: <start> I have to know the truth . <end>\n",
            "Target: <start> Tengo que saber la verdad . <end>\n",
            "Translation: tengo que saber la verdad . <end>\n",
            "\n",
            "Epoch #80, Loss 0.0748, Time 12.17 sec\n",
            "Input: <start> This is very bad . <end>\n",
            "Target: <start> Esto es muy malo . <end>\n",
            "Translation: este es la mitad . <end>\n",
            "\n",
            "Epoch #90, Loss 0.0836, Time 11.92 sec\n",
            "Input: <start> I thought he wouldn t come . <end>\n",
            "Target: <start> Pense que el no vendria . <end>\n",
            "Translation: pense que tom no esta tan inteligente . <end>\n",
            "\n",
            "Epoch #100, Loss 0.0545, Time 12.58 sec\n",
            "Input: <start> He is still in bed . <end>\n",
            "Target: <start> El aun esta en cama . <end>\n",
            "Translation: el esta engordando . <end>\n",
            "\n",
            "Epoch #110, Loss 0.0430, Time 11.62 sec\n",
            "Input: <start> Are you still sleepy ? <end>\n",
            "Target: <start> ¿ Todavia tienes sueno ? <end>\n",
            "Translation: ¿ estas todavia ? <end>\n",
            "\n",
            "Epoch #120, Loss 0.0589, Time 12.32 sec\n",
            "Input: <start> Tom seems to be rich . <end>\n",
            "Target: <start> Tom parece ser rico . <end>\n",
            "Translation: tom no quiere comer . <end>\n",
            "\n",
            "Epoch #130, Loss 0.1516, Time 11.66 sec\n",
            "Input: <start> Did you come to town ? <end>\n",
            "Target: <start> ¿ Vinisteis a la ciudad ? <end>\n",
            "Translation: ¿ vinisteis a la ciudad ? <end>\n",
            "\n",
            "Epoch #140, Loss 0.0270, Time 11.66 sec\n",
            "Input: <start> I want to tell you a story . <end>\n",
            "Target: <start> Quiero contarte un historia . <end>\n",
            "Translation: quiero contarte un historia . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0343, Time 11.62 sec\n",
            "Input: <start> You did fine , Tom . <end>\n",
            "Target: <start> Lo hiciste bien , Tom . <end>\n",
            "Translation: lo hiciste bien , tom . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0381, Time 11.64 sec\n",
            "Input: <start> Burj Khalifa is currently the tallest skyscraper in the world . <end>\n",
            "Target: <start> El Burj Khalifa es actualmente el mas alto rascacielos del mundo . <end>\n",
            "Translation: el burj khalifa es la casi correcta es convertirme en la segunda guerra . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0338, Time 12.11 sec\n",
            "Input: <start> Pardon me for interrupting you . <end>\n",
            "Target: <start> Dispense usted que le interrumpa . <end>\n",
            "Translation: dispense usted que le interrumpa . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0291, Time 11.62 sec\n",
            "Input: <start> Don t you want to win ? <end>\n",
            "Target: <start> ¿ No quieres ganar ? <end>\n",
            "Translation: ¿ no quieres ganar tu problema ? <end>\n",
            "\n",
            "Epoch #190, Loss 0.0268, Time 11.59 sec\n",
            "Input: <start> I was lost in the crowd . <end>\n",
            "Target: <start> Estaba perdido entre la multitud . <end>\n",
            "Translation: estaba perdido entre el ano pasado el cabello . <end>\n",
            "\n",
            "Epoch #200, Loss 0.0156, Time 11.65 sec\n",
            "Input: <start> He grew up in Australia . <end>\n",
            "Target: <start> El crecio en Australia . <end>\n",
            "Translation: el crecio en australia . <end>\n",
            "\n",
            "Epoch #210, Loss 0.0243, Time 11.80 sec\n",
            "Input: <start> The ticket is good through Monday . <end>\n",
            "Target: <start> El billete es valido hasta el lunes . <end>\n",
            "Translation: el billete es valido hasta el lunes . <end>\n",
            "\n",
            "Epoch #220, Loss 0.0464, Time 11.59 sec\n",
            "Input: <start> Tom says he doesn t remember a thing . <end>\n",
            "Target: <start> Tom dice que no recuerda nada . <end>\n",
            "Translation: tom dice que no lo voy a hacer eso . <end>\n",
            "\n",
            "Epoch #230, Loss 0.0548, Time 12.33 sec\n",
            "Input: <start> Who s faster , you or Tom ? <end>\n",
            "Target: <start> ¿ Quien es mas rapido vos o Tomas ? <end>\n",
            "Translation: ¿ quien de esta yo la puerta ? <end>\n",
            "\n",
            "Epoch #240, Loss 0.0126, Time 11.62 sec\n",
            "Input: <start> I love being here . <end>\n",
            "Target: <start> Me encanta estar aqui . <end>\n",
            "Translation: me encanta estar aqui . <end>\n",
            "\n",
            "Epoch #250, Loss 0.0616, Time 12.55 sec\n",
            "Input: <start> I ll go on my own . <end>\n",
            "Target: <start> Ire sola . <end>\n",
            "Translation: ire sola . <end>\n",
            "\n",
            "Epoch #260, Loss 0.0276, Time 11.59 sec\n",
            "Input: <start> They re wonderful . <end>\n",
            "Target: <start> Ustedes son maravillosos . <end>\n",
            "Translation: ustedes son maravillosos . <end>\n",
            "\n",
            "Epoch #270, Loss 0.0617, Time 11.71 sec\n",
            "Input: <start> This dictionary has volumes . <end>\n",
            "Target: <start> Este diccionario tiene doce tomos . <end>\n",
            "Translation: este diccionario tiene doce tomos . <end>\n",
            "\n",
            "Epoch #280, Loss 0.0260, Time 11.53 sec\n",
            "Input: <start> What makes you think that Tom is Canadian ? <end>\n",
            "Target: <start> ¿ Que te hace pensar que Tom es canadiense ? <end>\n",
            "Translation: ¿ que te hace pensar que tom esta haciendo ? <end>\n",
            "\n",
            "Epoch #290, Loss 0.0096, Time 11.59 sec\n",
            "Input: <start> Tom has a lot of people to see tomorrow morning . <end>\n",
            "Target: <start> Tom tiene que ver a un monton de gente manana por la manana . <end>\n",
            "Translation: tom tiene que pagar en absoluto en la habitacion . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OhGierZMQyK9",
        "colab_type": "code",
        "outputId": "62ee4db2-6451-42d4-8ba2-11e8ee10cf83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Test code for BLEU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(20):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=21.25893852524593, counts=[105, 46, 18, 12], totals=[182, 162, 142, 122], precisions=[57.69230769230769, 28.395061728395063, 12.67605633802817, 9.836065573770492], bp=1.0, sys_len=182, ref_len=180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7YyijjLcvu6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4. Train Model 2: translate from Spanish to English"
      ]
    },
    {
      "metadata": {
        "id": "L444gcl7e1Dn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1. Prepare data for model2\n"
      ]
    },
    {
      "metadata": {
        "id": "j4tL981we0H9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(train_eng.shape)\n",
        "target_labels[:,0:train_eng.shape[1] -1] = train_eng[:,1:]\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_spa, train_eng, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5bsG7DZjfMTy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Train Model2: from Spanish to English"
      ]
    },
    {
      "metadata": {
        "id": "NtJ1SGR-fLkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step2(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder2(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder2(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder2.trainable_variables + decoder2.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Ayomy6DQyOI",
        "colab_type": "code",
        "outputId": "f11c8076-1a41-4462-a7d0-bf0670247466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2587
        }
      },
      "cell_type": "code",
      "source": [
        "encoder2 = Encoder(spa_vocab_size)\n",
        "decoder2 = Decoder(eng_vocab_size)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder2.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step2(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate(flag=2)\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 0.7288, Time 14.30 sec\n",
            "Input: <start> ¿ Por que todo me pasa a mi ? <end>\n",
            "Target: <start> Why does everything happen to me ? <end>\n",
            "Translation: i m not a lot . <end>\n",
            "\n",
            "Epoch #10, Loss 0.5499, Time 11.20 sec\n",
            "Input: <start> Estoy lleno . <end>\n",
            "Target: <start> I am full . <end>\n",
            "Translation: i m not going to get a long time for you . <end>\n",
            "\n",
            "Epoch #20, Loss 0.4211, Time 11.18 sec\n",
            "Input: <start> Acabo de hacer un amigo . <end>\n",
            "Target: <start> I just made a friend . <end>\n",
            "Translation: i m not a little early . <end>\n",
            "\n",
            "Epoch #30, Loss 0.3622, Time 11.19 sec\n",
            "Input: <start> Lo llame al llegar a Tokio . <end>\n",
            "Target: <start> On arriving in Tokyo , I called him up . <end>\n",
            "Translation: don t make fun of that . <end>\n",
            "\n",
            "Epoch #40, Loss 0.3247, Time 12.29 sec\n",
            "Input: <start> Estaremos en contacto . <end>\n",
            "Target: <start> We ll be in touch . <end>\n",
            "Translation: we re not a day . <end>\n",
            "\n",
            "Epoch #50, Loss 0.2715, Time 11.21 sec\n",
            "Input: <start> Mi casa esta cerca del parque . <end>\n",
            "Target: <start> My house is close to the park . <end>\n",
            "Translation: my house is close to the park . <end>\n",
            "\n",
            "Epoch #60, Loss 0.2380, Time 11.30 sec\n",
            "Input: <start> Puedes empezar ahora mismo . <end>\n",
            "Target: <start> You can start right now . <end>\n",
            "Translation: you can t blame them . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2170, Time 11.28 sec\n",
            "Input: <start> Deberias tener mas cuidado la proxima vez . <end>\n",
            "Target: <start> You should be more careful the next time . <end>\n",
            "Translation: you should have completed it can you receive your christmas present for this day ? <end>\n",
            "\n",
            "Epoch #80, Loss 0.1985, Time 11.29 sec\n",
            "Input: <start> Apenas conozco a Tom . <end>\n",
            "Target: <start> I barely know Tom . <end>\n",
            "Translation: i asked him to help you with tom again . <end>\n",
            "\n",
            "Epoch #90, Loss 0.2106, Time 11.25 sec\n",
            "Input: <start> Te devolvere el CD dentro de una semana . <end>\n",
            "Target: <start> I will give you back the CD in a week . <end>\n",
            "Translation: he is a clever boy . <end>\n",
            "\n",
            "Epoch #100, Loss 0.1651, Time 11.17 sec\n",
            "Input: <start> Acabo de hacer un amigo . <end>\n",
            "Target: <start> I just made a friend . <end>\n",
            "Translation: i want to be a good teacher . <end>\n",
            "\n",
            "Epoch #110, Loss 0.1670, Time 12.40 sec\n",
            "Input: <start> Deje la casa de mis padres para vivir por mi cuenta . <end>\n",
            "Target: <start> I moved out of my parent s house to live on my own . <end>\n",
            "Translation: i had borrowed a car . <end>\n",
            "\n",
            "Epoch #120, Loss 0.1675, Time 11.23 sec\n",
            "Input: <start> Tom le dio un beso rapido a Mary . <end>\n",
            "Target: <start> Tom gave Mary a quick kiss . <end>\n",
            "Translation: tom can t swim class . <end>\n",
            "\n",
            "Epoch #130, Loss 0.1603, Time 11.30 sec\n",
            "Input: <start> Los nuevos disenos son mucho mejores que los viejos . <end>\n",
            "Target: <start> The new designs are much better than the old ones . <end>\n",
            "Translation: the new child told that that it looked like to life to see the floor . <end>\n",
            "\n",
            "Epoch #140, Loss 0.1569, Time 11.23 sec\n",
            "Input: <start> ¿ Que hiciste el ano pasado en el dia de Navidad ? <end>\n",
            "Target: <start> What did you do last year on Christmas Day ? <end>\n",
            "Translation: what did you do this on you ? <end>\n",
            "\n",
            "Epoch #150, Loss 0.1736, Time 11.21 sec\n",
            "Input: <start> Acabamos de comer sushi y tomar cerveza . <end>\n",
            "Target: <start> We just ate sushi and drank beer . <end>\n",
            "Translation: we have someone else in time . <end>\n",
            "\n",
            "Epoch #160, Loss 0.1336, Time 11.29 sec\n",
            "Input: <start> Mary tiene un par de anos mas que Tom . <end>\n",
            "Target: <start> Mary is a few years older than Tom . <end>\n",
            "Translation: mary has two boyfriends . <end>\n",
            "\n",
            "Epoch #170, Loss 0.1351, Time 11.26 sec\n",
            "Input: <start> Tom es mas estupido de lo que crees . <end>\n",
            "Target: <start> Tom is stupider than you think . <end>\n",
            "Translation: tom is a good teacher . <end>\n",
            "\n",
            "Epoch #180, Loss 0.1351, Time 12.22 sec\n",
            "Input: <start> Pareces ocupado . <end>\n",
            "Target: <start> You look busy . <end>\n",
            "Translation: you look busy . <end>\n",
            "\n",
            "Epoch #190, Loss 0.1166, Time 12.11 sec\n",
            "Input: <start> Tom penso que la casa que Mary queria comprar era un poco pequena . <end>\n",
            "Target: <start> Tom thought the house Mary wanted to buy was a little too small . <end>\n",
            "Translation: tom spent hours looking at me . <end>\n",
            "\n",
            "Epoch #200, Loss 0.1118, Time 11.29 sec\n",
            "Input: <start> Ayer no fui , de manera que tengo que ir hoy . <end>\n",
            "Target: <start> I didn t go yesterday , so I have to go today . <end>\n",
            "Translation: i didn t ever sit either . <end>\n",
            "\n",
            "Epoch #210, Loss 0.1192, Time 11.14 sec\n",
            "Input: <start> ¿ Puedo invitaros a cenar ? <end>\n",
            "Target: <start> May I invite you to dinner ? <end>\n",
            "Translation: may i do what we do this ? <end>\n",
            "\n",
            "Epoch #220, Loss 0.1360, Time 11.27 sec\n",
            "Input: <start> Ella tiene una letra muy bonita . <end>\n",
            "Target: <start> She has very nice looking handwriting . <end>\n",
            "Translation: she has forgiven him . <end>\n",
            "\n",
            "Epoch #230, Loss 0.1082, Time 11.57 sec\n",
            "Input: <start> Vino de una de las familias mas ricas de America . <end>\n",
            "Target: <start> He came from one of the richest families in the United States . <end>\n",
            "Translation: he is a frank person and easy to talk to . <end>\n",
            "\n",
            "Epoch #240, Loss 0.1117, Time 11.23 sec\n",
            "Input: <start> Estaria encantado de ayudarte , solo que ahora mismo estoy muy ocupado . <end>\n",
            "Target: <start> I would gladly help you , only I am too busy now . <end>\n",
            "Translation: i would gladly help you . <end>\n",
            "\n",
            "Epoch #250, Loss 0.1160, Time 11.96 sec\n",
            "Input: <start> Olvidemonos de lo que sucedio hoy . <end>\n",
            "Target: <start> Let s forget about what happened today . <end>\n",
            "Translation: let s forget about the truth . <end>\n",
            "\n",
            "Epoch #260, Loss 0.1196, Time 11.25 sec\n",
            "Input: <start> Es una cantante famosa . <end>\n",
            "Target: <start> She is a famous singer . <end>\n",
            "Translation: she is a modern girl . <end>\n",
            "\n",
            "Epoch #270, Loss 0.0924, Time 11.51 sec\n",
            "Input: <start> Voy a hacer lo que se me ha dicho . <end>\n",
            "Target: <start> I m going to do what I ve been told . <end>\n",
            "Translation: i m going to do that on the meeting . <end>\n",
            "\n",
            "Epoch #280, Loss 0.1425, Time 11.24 sec\n",
            "Input: <start> Ella no tiene modales . <end>\n",
            "Target: <start> She has no manners . <end>\n",
            "Translation: she s big years old . <end>\n",
            "\n",
            "Epoch #290, Loss 0.0954, Time 11.22 sec\n",
            "Input: <start> Estoy segura que vas a encontrar algo en la heladera . <end>\n",
            "Target: <start> I m sure you ll find something in the refrigerator . <end>\n",
            "Translation: i m a little child next week . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yk3deGx8fKMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8541c15e-f4d2-4efe-b108-9cb45d9fe2c3"
      },
      "cell_type": "code",
      "source": [
        "# Test code for BLEU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(20):\n",
        "  input_sent, target_sent, translation = translate(flag=2)\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=23.042201784404728, counts=[104, 49, 24, 19], totals=[195, 175, 155, 135], precisions=[53.333333333333336, 28.0, 15.483870967741936, 14.074074074074074], bp=0.9647392360230109, sys_len=195, ref_len=202)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WqSWEDDzfKPq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLgzr_V2hZ1n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5. Back-translate\n",
        "Use your two models to translate a sentence from English to Spanish, and then back to English. Compare the original sentence, and the back-translated sentence. Repeat this using an evaluation corpus of 1,000 sentences, and report the BLEU score."
      ]
    },
    {
      "metadata": {
        "id": "ZuiyrsAUOvyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.1. Preprocess test data"
      ]
    },
    {
      "metadata": {
        "id": "vU2Ifd1rhmZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = shuffled_data[selected_id[ntrain:], :]\n",
        "test_data = [(preprocess(eng), preprocess(spa)) for (eng, spa) in test_data]\n",
        "#print(train_data[0])\n",
        "test_eng, test_spa = list(zip(*test_data))\n",
        "test_eng = eng_tokenizer.texts_to_sequences(test_eng)\n",
        "test_eng = tf.keras.preprocessing.sequence.pad_sequences(test_eng, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwRO9rDnO0UL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.2. Using Model 1 to translate test data from English to Spanish."
      ]
    },
    {
      "metadata": {
        "id": "oFmTgv5qfKTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "middle_spa = []\n",
        "origin_eng = []\n",
        "for i in range(ntest):\n",
        "  input_sent, target_sent, translation = translate(idx=i, flag=3)\n",
        "  #print(input_sent)\n",
        "  origin_eng.append(input_sent)\n",
        "  middle_spa.append(translation[:-5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63IpkexsO9Sk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.3. Using Model 2 to translate the output from Model 1 back to English"
      ]
    },
    {
      "metadata": {
        "id": "gi3v5GaKBhgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_spa = spa_tokenizer.texts_to_sequences(middle_spa)\n",
        "input_spa = tf.keras.preprocessing.sequence.pad_sequences(input_spa, padding='post')\n",
        "#print(input_spa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYyzBqvEhmeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "back_eng = []\n",
        "for i in range(ntest):\n",
        "  input_sent, target_sent, translation = translate(idx=i, flag=4)\n",
        "  #print(translation)\n",
        "  back_eng.append(\"<start> \" + translation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4LvXYUrPGT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.4. Calculate BLEU"
      ]
    },
    {
      "metadata": {
        "id": "b5M_5-z9Gu3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0a23f87e-fed2-4766-acb2-7fa6fe0fefe6"
      },
      "cell_type": "code",
      "source": [
        "results = sacrebleu.raw_corpus_bleu(back_eng, [origin_eng])\n",
        "print(results)  "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=0.0, counts=[3089, 829, 3, 0], totals=[9928, 8928, 7928, 6928], precisions=[31.114020950846093, 9.285394265232975, 0.037840565085771945, 0.0], bp=1.0, sys_len=9928, ref_len=9658)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}