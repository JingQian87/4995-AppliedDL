{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faP_TfySH12q"
   },
   "source": [
    "# Assignment 5 Machine Translation\n",
    "### Jing Qian (jq2282)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhk7LSRmH3H7"
   },
   "source": [
    "## Step 1. Install packages and load libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "TkZU21YuHt1Y",
    "outputId": "d92abffa-f6a2-4020-a1b6-37523478e96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 332.1MB 55kB/s \n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 7.5MB/s \n",
      "\u001b[K    100% |████████████████████████████████| 419kB 11.2MB/s \n",
      "\u001b[K    100% |████████████████████████████████| 61kB 20.0MB/s \n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading https://files.pythonhosted.org/packages/12/5b/7196b11bca204cb6ca9000b5dc910e809081f224c73ef28e9991080e4e51/sacrebleu-1.3.1.tar.gz\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
      "Building wheels for collected packages: sacrebleu\n",
      "  Building wheel for sacrebleu (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/56/c0/fb/1c7f9b3a71f64cdf86291cc645596f71746807bf2f72b3c1dd\n",
      "Successfully built sacrebleu\n",
      "Installing collected packages: sacrebleu\n",
      "Successfully installed sacrebleu-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
    "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bIPY-Wq6H0wK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import sacrebleu\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXGdnexoH_5q"
   },
   "source": [
    "## Step 2. Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tq8ETDnxJODV"
   },
   "source": [
    "### 2.1. Load and select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2diHj7jsIFOj"
   },
   "outputs": [],
   "source": [
    "ntrain = 50\n",
    "ntest = 10\n",
    "nall = ntrain + ntest\n",
    "nepoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "p7LoioJgIO97",
    "outputId": "6347de50-4c72-48ab-a7cf-76481b08287a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SLRG0JchISlU"
   },
   "outputs": [],
   "source": [
    "def load(fname):\n",
    "  # Load the file using std open\n",
    "  f = open(fname, 'r')\n",
    "  text = []\n",
    "  for line in f.readlines():\n",
    "    text.append(line.replace('\\n','').split('\\t'))\n",
    "    \n",
    "  f.close()\n",
    "  return text\n",
    "\n",
    "data = load('/content/gdrive/My Drive/spa-eng/spa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "sBcVdFi2IUaO",
    "outputId": "448f02a7-d1ec-4019-cdaa-1b8137988c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Fire!', '¡Disparad!'], ['Help!', '¡Ayuda!'], ['Help!', '¡Socorro! ¡Auxilio!'], ['Help!', '¡Auxilio!'], ['Jump!', '¡Salta!']]\n",
      "(118964, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data[10:15])\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pvd5zQBYI0iv"
   },
   "source": [
    "注意，写好之后把seed comment out!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mGNOKNclIYC-",
    "outputId": "5fa00a1c-3c82-482e-8880-f3c82a9df39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2) (10, 2)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "shuffled_data = np.random.permutation(data)\n",
    "selected_id = np.random.randint(len(data), size = nall)\n",
    "train_data = shuffled_data[selected_id[:ntrain], :]\n",
    "test_data = shuffled_data[selected_id[ntrain:], :]\n",
    "print(np.shape(train_data_raw), np.shape(test_data_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skj36OdHJR-7"
   },
   "source": [
    "### 2.2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ndtl8GZZJUbZ"
   },
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
    "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
    "  s = re.sub(r'[\" \"]+', \" \", s)\n",
    "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
    "  s = s.strip()\n",
    "  s = '<start> ' + s + ' <end>'\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "XeZOk_9qJktc",
    "outputId": "60f4b96b-0b3f-4b8a-c7a1-7e1ec7a05ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<start> How do you think that makes me feel ? <end>', '<start> ¿ Como crees que me hace sentir eso ? <end>')\n"
     ]
    }
   ],
   "source": [
    "train_data = [(preprocess(eng), preprocess(spa)) for (eng, spa) in train_data]\n",
    "print(train_data[0])\n",
    "train_eng, train_spa = list(zip(*train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8yTgCvxAKKEg",
    "outputId": "4b5ff519-f9c8-44b0-dc0e-bb2230daa94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 23 20  5 37 24 60 15 61  8  2  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "eng_tokenizer.fit_on_texts(train_eng)\n",
    "train_eng = eng_tokenizer.texts_to_sequences(train_eng)\n",
    "train_eng = tf.keras.preprocessing.sequence.pad_sequences(train_eng, padding='post')\n",
    "print(train_eng[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a5JpJftKK8gY",
    "outputId": "8e56a20d-848b-487d-823b-18fc27d2e4b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  9 16 44  4 13 26 45 27 10  2  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "spa_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "spa_tokenizer.fit_on_texts(train_spa)\n",
    "train_spa = spa_tokenizer.texts_to_sequences(train_spa)\n",
    "train_spa = tf.keras.preprocessing.sequence.pad_sequences(train_spa, padding='post')\n",
    "print(train_spa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rs323ojHMrM_"
   },
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "spa_vocab_size = len(spa_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "h0jztFXOM6S1",
    "outputId": "e7b7f8ad-6b27-4cec-be85-f9af1a387f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> <start>\n",
      "23 -> how\n",
      "20 -> do\n",
      "5 -> you\n",
      "37 -> think\n",
      "24 -> that\n",
      "60 -> makes\n",
      "15 -> me\n",
      "61 -> feel\n",
      "8 -> ?\n",
      "2 -> <end>\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the correspondence between word and code, not used in model\n",
    "def decode(encoded, tokenizer):\n",
    "  for number in encoded:\n",
    "    if number !=0:\n",
    "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
    "      \n",
    "decode(train_eng[0], eng_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCfXlH0AIo6f"
   },
   "source": [
    "## Step 3. Train Model 1: translate from English to Spanish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mq3UxYQzNNsg"
   },
   "source": [
    "### 3.1. Prepare data for model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "a0eLXu-NIoNK",
    "outputId": "8ec6572e-7f41-4daf-80f7-9ba6ea7dae33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sequence [ 1  9 16 44  4 13 26 45 27 10  2  0  0  0  0  0  0]\n",
      "Target label [ 9. 16. 44.  4. 13. 26. 45. 27. 10.  2.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Create labels for the decoder by shifting the target sequence\n",
    "# one to the right.\n",
    "target_labels = np.zeros(train_spa.shape)\n",
    "target_labels[:,0:train_spa.shape[1] -1] = train_spa[:,1:]\n",
    "\n",
    "print(\"Target sequence\", train_spa[0])\n",
    "print(\"Target label\", target_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qafjzAUJN-fN"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_eng, train_spa, target_labels)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-QRBV9vaOJ_V",
    "outputId": "fbf1f0b9-74fa-4c19-bbfc-200f5b3c726f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (5, 17) (5, 17) (5, 17)\n"
     ]
    }
   ],
   "source": [
    "# Test code!\n",
    "example_batch = next(iter(dataset))\n",
    "source, target, taget_labels = example_batch\n",
    "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f95J-IkqQ6xv"
   },
   "source": [
    "### 3.2. General components for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yCs_-y6FOPZZ"
   },
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "rnn_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UrHuydEsOmPp"
   },
   "outputs": [],
   "source": [
    "# Differ from example, add source_vocab_size to initialization\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, source_vocab_size):\n",
    "    super(Encoder, self).__init__()\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
    "                                               embedding_size)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "    \n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state=hidden)        \n",
    "    return output, state\n",
    "  \n",
    "  def init_state(self, batch_size):\n",
    "    return tf.zeros((batch_size, rnn_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AqWK4AHTOvBQ"
   },
   "outputs": [],
   "source": [
    "# Test code!\n",
    "# Create a batch of one sentence\n",
    "ex_sentence = tf.expand_dims(train_eng[0], axis=0)\n",
    "ex_translation = tf.expand_dims(train_spa[0], axis=0)\n",
    "ex_labels = tf.expand_dims(target_labels[0], axis=0)\n",
    "print(ex_sentence.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TECibZsPQokh"
   },
   "outputs": [],
   "source": [
    "# Differ from example, add target_vocab_size to initialization\n",
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, target_vocab_size):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
    "                                               embedding_size)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "    logits = self.dense(output)\n",
    "    return logits, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yo5xNFnJQyBw"
   },
   "outputs": [],
   "source": [
    "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def calc_loss(targets, logits):\n",
    "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "  mask = tf.cast(mask, dtype=tf.int64)\n",
    "  return crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "#print(\"Loss\", calc_loss(ex_labels, decoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cUM198fKQyEo"
   },
   "outputs": [],
   "source": [
    "def translate(idx=None, flag=1):\n",
    "  \n",
    "    if idx == None: \n",
    "      idx = np.random.choice(len(train_data))\n",
    "    \n",
    "    if flag == 1:\n",
    "      source_data = train_eng\n",
    "      target_tokenizer = spa_tokenizer\n",
    "      encoder = encoder1\n",
    "      decoder = decoder1\n",
    "      tmp0, tmp1 = train_data[idx][0], train_data[idx][1]\n",
    "    elif flag == 2:\n",
    "      source_data = train_spa\n",
    "      target_tokenizer = eng_tokenizer\n",
    "      encoder = encoder2\n",
    "      decoder = decoder2\n",
    "      tmp0, tmp1 = train_data[idx][1], train_data[idx][0]      \n",
    "      \n",
    "    input_sent = source_data[idx]\n",
    "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
    "    \n",
    "    hidden_state = encoder.init_state(batch_size=1)\n",
    "    output, hidden_state = encoder(input_sent, hidden_state)\n",
    "    \n",
    "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
    "    out_words = []\n",
    "    \n",
    "    decoder_state = hidden_state\n",
    "\n",
    "    while True:\n",
    "      \n",
    "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
    "        decoder_input = tf.argmax(decoder_output, -1)\n",
    "        word_idx = decoder_input.numpy()[0][0]\n",
    "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
    "        # before the decoder is trained, just stop translating and return\n",
    "        # what we have)\n",
    "        if word_idx == 0: \n",
    "          out_words.append('<end>')\n",
    "        else:\n",
    "          out_words.append(target_tokenizer.index_word[word_idx])\n",
    "\n",
    "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
    "          break\n",
    "          \n",
    "    translation = ' '.join(out_words)    \n",
    "    return tmp0, tmp1, translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "c7YSgbsvQyIB",
    "outputId": "514f7345-e67d-4651-cbde-3c9d920e5738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: He was impatient to see his son.\n",
      "Target: Él estaba impaciente por ver a su hijo.\n",
      "Translation: de minima minima traje alternativa de estamos tenemos al al ¿ o mi preparar toda tan retrasa fui le horario\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "input_sent, target_sent, translation = translate()\n",
    "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "spcI0A4HWRQe"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HXX5F79WUIy"
   },
   "source": [
    "### 3.3. Train Model 1: from English to Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Np7vJsGQWcin"
   },
   "outputs": [],
   "source": [
    "#@tf.function # remove this annotation when debugging\n",
    "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    encoder_output, encoder_state = encoder1(source_seq, initial_state)\n",
    "    logits, decoder_state = decoder1(target_seq, encoder_state)\n",
    "    loss = calc_loss(target_labels, logits)\n",
    "\n",
    "  variables = encoder1.trainable_variables + decoder1.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2587
    },
    "colab_type": "code",
    "id": "vHm1Riq8YH-0",
    "outputId": "3325685a-4154-4be7-d383-cd334bada5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Loss 3.5549, Time 1.05 sec\n",
      "Input: <start> Please stop talking . <end>\n",
      "Target: <start> Por favor , deja de hablar . <end>\n",
      "Translation: ¿ <end>\n",
      "\n",
      "Epoch #10, Loss 2.9324, Time 0.89 sec\n",
      "Input: <start> He was impatient to see his son . <end>\n",
      "Target: <start> El estaba impaciente por ver a su hijo . <end>\n",
      "Translation: ¿ ¿ no . <end>\n",
      "\n",
      "Epoch #20, Loss 2.6806, Time 0.89 sec\n",
      "Input: <start> She didn t buy bread . <end>\n",
      "Target: <start> No compro el pan . <end>\n",
      "Translation: ¿ el que que que . <end>\n",
      "\n",
      "Epoch #30, Loss 2.4072, Time 0.88 sec\n",
      "Input: <start> I m an engineer . <end>\n",
      "Target: <start> Soy ingeniero . <end>\n",
      "Translation: ¿ el me que tomas ? <end>\n",
      "\n",
      "Epoch #40, Loss 2.0823, Time 0.88 sec\n",
      "Input: <start> I drove all night . <end>\n",
      "Target: <start> Conduje toda la noche . <end>\n",
      "Translation: ¿ me me tomas ? <end>\n",
      "\n",
      "Epoch #50, Loss 1.6941, Time 0.96 sec\n",
      "Input: <start> Let s hope Tom didn t do what you think he did . <end>\n",
      "Target: <start> Esperemos que Tom no haya hecho lo que pensas que hizo . <end>\n",
      "Translation: no una que tomas muchas de ? <end>\n",
      "\n",
      "Epoch #60, Loss 1.3127, Time 0.88 sec\n",
      "Input: <start> She danced with a grace that surprised us all . <end>\n",
      "Target: <start> Ella bailo con una elegancia que nos sorprendio a todos . <end>\n",
      "Translation: ¿ me puede revelar este rollo ? <end>\n",
      "\n",
      "Epoch #70, Loss 0.9555, Time 0.91 sec\n",
      "Input: <start> He doesn t know what to do with his money . <end>\n",
      "Target: <start> El no sabe que hacer con su dinero . <end>\n",
      "Translation: el golpeo la puerta muchas veces , no pudimos jugar al tenis fuera . <end>\n",
      "\n",
      "Epoch #80, Loss 0.6865, Time 0.88 sec\n",
      "Input: <start> There is a small pond in our garden . <end>\n",
      "Target: <start> Hay un pequeno estanque en nuestro jardin . <end>\n",
      "Translation: ¿ me necesitas , estare porai . <end>\n",
      "\n",
      "Epoch #90, Loss 0.4997, Time 0.88 sec\n",
      "Input: <start> Tom plays the harmonica by ear . <end>\n",
      "Target: <start> Tom toca la armonica de oido . <end>\n",
      "Translation: no comi desde el desayuno , estoy hambriento . <end>\n",
      "\n",
      "Epoch #100, Loss 0.3848, Time 0.88 sec\n",
      "Input: <start> If you need me , I ll be somewhere around . <end>\n",
      "Target: <start> Si me necesitas , estare porai . <end>\n",
      "Translation: ojala pudiera pasar mas tiempo contigo . <end>\n",
      "\n",
      "Epoch #110, Loss 0.3088, Time 0.89 sec\n",
      "Input: <start> I d like another beer . <end>\n",
      "Target: <start> Quiero una cerveza mas . <end>\n",
      "Translation: ¿ es aceptable el precio ? <end>\n",
      "\n",
      "Epoch #120, Loss 0.2589, Time 1.04 sec\n",
      "Input: <start> I thought my parents would be proud of me . <end>\n",
      "Target: <start> Pense que mis padres estarian orgullosos de mi . <end>\n",
      "Translation: pense que mis padres estarian orgullosos de mi . <end>\n",
      "\n",
      "Epoch #130, Loss 0.2188, Time 0.88 sec\n",
      "Input: <start> I wish I could play the flute as well as Ian Anderson . <end>\n",
      "Target: <start> Desearia poder tocar la flauta traversa tan bien como Anderson . <end>\n",
      "Translation: desearia poder tocar la flauta traversa tan bien como anderson . <end>\n",
      "\n",
      "Epoch #140, Loss 0.1903, Time 0.89 sec\n",
      "Input: <start> Can I have this film developed ? <end>\n",
      "Target: <start> ¿ Me puede revelar este rollo ? <end>\n",
      "Translation: ¿ me puede revelar este rollo ? <end>\n",
      "\n",
      "Epoch #150, Loss 0.1695, Time 0.89 sec\n",
      "Input: <start> Come see me . <end>\n",
      "Target: <start> Venga a verme . <end>\n",
      "Translation: ¿ es aceptable el precio ? <end>\n",
      "\n",
      "Epoch #160, Loss 0.1521, Time 0.90 sec\n",
      "Input: <start> I overslept and was late for school . <end>\n",
      "Target: <start> Me quede dormido y llegue tarde al colegio . <end>\n",
      "Translation: me duche y me fui a la cama . <end>\n",
      "\n",
      "Epoch #170, Loss 0.1425, Time 0.89 sec\n",
      "Input: <start> If you need me , I ll be somewhere around . <end>\n",
      "Target: <start> Si me necesitas , estare porai . <end>\n",
      "Translation: ojala pudiera pasar mas tiempo contigo . <end>\n",
      "\n",
      "Epoch #180, Loss 0.1494, Time 0.93 sec\n",
      "Input: <start> More often than not , he is late for school . <end>\n",
      "Target: <start> El se retrasa frecuentemente en la escuela . <end>\n",
      "Translation: el estaba impaciente por ver a su hijo . <end>\n",
      "\n",
      "Epoch #190, Loss 0.1194, Time 0.89 sec\n",
      "Input: <start> I overslept and was late for school . <end>\n",
      "Target: <start> Me quede dormido y llegue tarde al colegio . <end>\n",
      "Translation: me duche y me fui a la cama . <end>\n",
      "\n",
      "Epoch #200, Loss 0.1120, Time 0.88 sec\n",
      "Input: <start> Is this price acceptable ? <end>\n",
      "Target: <start> ¿ Es aceptable el precio ? <end>\n",
      "Translation: ¿ es aceptable el precio ? <end>\n",
      "\n",
      "Epoch #210, Loss 0.1048, Time 0.88 sec\n",
      "Input: <start> If you need me , I ll be somewhere around . <end>\n",
      "Target: <start> Si me necesitas , estare porai . <end>\n",
      "Translation: ojala pudiera pasar mas tiempo contigo . <end>\n",
      "\n",
      "Epoch #220, Loss 0.0989, Time 0.89 sec\n",
      "Input: <start> How do you think that makes me feel ? <end>\n",
      "Target: <start> ¿ Como crees que me hace sentir eso ? <end>\n",
      "Translation: ¿ como crees que me hace sentir eso ? <end>\n",
      "\n",
      "Epoch #230, Loss 0.0918, Time 0.88 sec\n",
      "Input: <start> I m an engineer . <end>\n",
      "Target: <start> Soy ingeniero . <end>\n",
      "Translation: venga a verme . <end>\n",
      "\n",
      "Epoch #240, Loss 0.0855, Time 0.90 sec\n",
      "Input: <start> Can you believe it ? He s even lazier than me . <end>\n",
      "Target: <start> ¿ Te lo puedes creer ? El es todavia mas vago que yo . <end>\n",
      "Translation: ¿ estas seguro de no haber olvidado nada ? <end>\n",
      "\n",
      "Epoch #250, Loss 0.0786, Time 0.88 sec\n",
      "Input: <start> These tomatoes don t have any taste . <end>\n",
      "Target: <start> Estos tomates no saben a nada . <end>\n",
      "Translation: ¿ cuanto tiempo puedo tomar prestado este libro ? <end>\n",
      "\n",
      "Epoch #260, Loss 0.0725, Time 0.89 sec\n",
      "Input: <start> I have no alternative . <end>\n",
      "Target: <start> No tengo alternativa . <end>\n",
      "Translation: no tengo alternativa . <end>\n",
      "\n",
      "Epoch #270, Loss 0.0644, Time 0.88 sec\n",
      "Input: <start> Please stop talking . <end>\n",
      "Target: <start> Por favor , deja de hablar . <end>\n",
      "Translation: tom toca la armonica de oido . <end>\n",
      "\n",
      "Epoch #280, Loss 0.0581, Time 0.89 sec\n",
      "Input: <start> She danced with a grace that surprised us all . <end>\n",
      "Target: <start> Ella bailo con una elegancia que nos sorprendio a todos . <end>\n",
      "Translation: ella bailo con una elegancia que nos sorprendio a todos . <end>\n",
      "\n",
      "Epoch #290, Loss 0.0527, Time 0.88 sec\n",
      "Input: <start> Is this price acceptable ? <end>\n",
      "Target: <start> ¿ Es aceptable el precio ? <end>\n",
      "Translation: ¿ es aceptable el precio ? <end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = nepoch\n",
    "\n",
    "encoder1 = Encoder(eng_vocab_size)\n",
    "decoder1 = Decoder(spa_vocab_size)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "  \n",
    "    en_initial_states = encoder1.init_state(batch_size)\n",
    "    \n",
    "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
    "      loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
    "      elapsed = time.time() - start\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
    "      input_sent, target_sent, translation = translate()\n",
    "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OhGierZMQyK9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7YyijjLcvu6"
   },
   "source": [
    "## Step 4. Train Model 2: translate from Spanish to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3Ayomy6DQyOI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "uhk7LSRmH3H7"
   ],
   "name": "A5_jq2282_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
