{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A5_jq2282_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "uhk7LSRmH3H7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "faP_TfySH12q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 5 Machine Translation\n",
        "### Jing Qian (jq2282)"
      ]
    },
    {
      "metadata": {
        "id": "uhk7LSRmH3H7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1. Install packages and load libraries\n"
      ]
    },
    {
      "metadata": {
        "id": "TkZU21YuHt1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2de1fc82-cd42-40cb-eb69-2086849c24d1"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bIPY-Wq6H0wK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXGdnexoH_5q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2. Load and preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "Tq8ETDnxJODV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1. Load and select data"
      ]
    },
    {
      "metadata": {
        "id": "2diHj7jsIFOj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ntrain = 500\n",
        "ntest = 100\n",
        "nall = ntrain + ntest\n",
        "nepoch = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7LoioJgIO97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e8c9d964-2903-42cf-a881-307bf2e86a37"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SLRG0JchISlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load(fname):\n",
        "  # Load the file using std open\n",
        "  f = open(fname, 'r')\n",
        "  text = []\n",
        "  for line in f.readlines():\n",
        "    text.append(line.replace('\\n','').split('\\t'))\n",
        "    \n",
        "  f.close()\n",
        "  return text\n",
        "\n",
        "data = load('/content/gdrive/My Drive/spa-eng/spa.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sBcVdFi2IUaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f9b50b81-9f75-4ad4-8705-432b79d87ad1"
      },
      "cell_type": "code",
      "source": [
        "print(data[10:15])\n",
        "print(np.shape(data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Fire!', '¡Disparad!'], ['Help!', '¡Ayuda!'], ['Help!', '¡Socorro! ¡Auxilio!'], ['Help!', '¡Auxilio!'], ['Jump!', '¡Salta!']]\n",
            "(118964, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pvd5zQBYI0iv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "注意，写好之后把seed comment out!!!"
      ]
    },
    {
      "metadata": {
        "id": "mGNOKNclIYC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b01c286-7a37-4051-cb94-c92e266a39de"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n",
        "shuffled_data = np.random.permutation(data)\n",
        "selected_id = np.random.randint(len(data), size = nall)\n",
        "train_data = shuffled_data[selected_id[:ntrain], :]\n",
        "print(np.shape(train_data), np.shape(shuffled_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 2) (118964, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "skj36OdHJR-7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2. Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "Ndtl8GZZJUbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XeZOk_9qJktc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "03e0b553-129f-450f-dc9d-888826d5c02e"
      },
      "cell_type": "code",
      "source": [
        "train_data = [(preprocess(eng), preprocess(spa)) for (eng, spa) in train_data]\n",
        "print(train_data[0])\n",
        "train_eng, train_spa = list(zip(*train_data))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('<start> How do you think that makes me feel ? <end>', '<start> ¿ Como crees que me hace sentir eso ? <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8yTgCvxAKKEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "598b9b86-dc45-4244-b893-aa182aa46968"
      },
      "cell_type": "code",
      "source": [
        "eng_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "eng_tokenizer.fit_on_texts(train_eng)\n",
        "train_eng = eng_tokenizer.texts_to_sequences(train_eng)\n",
        "train_eng = tf.keras.preprocessing.sequence.pad_sequences(train_eng, padding='post')\n",
        "print(train_eng[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1  47  20   7  88  16 369  17 103  10   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5JpJftKK8gY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "82dc1386-935a-42b5-e398-76758f4a9294"
      },
      "cell_type": "code",
      "source": [
        "spa_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "spa_tokenizer.fit_on_texts(train_spa)\n",
        "train_spa = spa_tokenizer.texts_to_sequences(train_spa)\n",
        "train_spa = tf.keras.preprocessing.sequence.pad_sequences(train_spa, padding='post')\n",
        "print(train_spa[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1  10  35 127   4  15  47 193  36  11   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rs323ojHMrM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "spa_vocab_size = len(spa_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h0jztFXOM6S1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c605874c-9d4d-4e58-c9e0-5586db531236"
      },
      "cell_type": "code",
      "source": [
        "# Demonstrate the correspondence between word and code, not used in model\n",
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "decode(train_eng[0], eng_tokenizer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "47 -> how\n",
            "20 -> do\n",
            "7 -> you\n",
            "88 -> think\n",
            "16 -> that\n",
            "369 -> makes\n",
            "17 -> me\n",
            "103 -> feel\n",
            "10 -> ?\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WCfXlH0AIo6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3. Train Model 1: translate from English to Spanish\n"
      ]
    },
    {
      "metadata": {
        "id": "mq3UxYQzNNsg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1. Prepare data for model1"
      ]
    },
    {
      "metadata": {
        "id": "a0eLXu-NIoNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "add31be2-c830-4494-cd19-b614ba3e5ef5"
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(train_spa.shape)\n",
        "target_labels[:,0:train_spa.shape[1] -1] = train_spa[:,1:]\n",
        "\n",
        "print(\"Target sequence\", train_spa[0])\n",
        "print(\"Target label\", target_labels[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [  1  10  35 127   4  15  47 193  36  11   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0]\n",
            "Target label [ 10.  35. 127.   4.  15.  47. 193.  36.  11.   2.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qafjzAUJN-fN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_eng, train_spa, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QRBV9vaOJ_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "363168c0-5434-4274-e523-120cbdf86bb0"
      },
      "cell_type": "code",
      "source": [
        "# Test code!\n",
        "# example_batch = next(iter(dataset))\n",
        "# source, target, taget_labels = example_batch\n",
        "# print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (5, 24) (5, 29) (5, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f95J-IkqQ6xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2. General components for models"
      ]
    },
    {
      "metadata": {
        "id": "yCs_-y6FOPZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "rnn_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrHuydEsOmPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Differ from example, add source_vocab_size to initialization\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, source_vocab_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqWK4AHTOvBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf52c5e2-a3dc-4ebc-81f9-f2359e40162d"
      },
      "cell_type": "code",
      "source": [
        "# Test code!\n",
        "# Create a batch of one sentence\n",
        "# ex_sentence = tf.expand_dims(train_eng[0], axis=0)\n",
        "# ex_translation = tf.expand_dims(train_spa[0], axis=0)\n",
        "# ex_labels = tf.expand_dims(target_labels[0], axis=0)\n",
        "# print(ex_sentence.shape)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TECibZsPQokh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Differ from example, add target_vocab_size to initialization\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, target_vocab_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yo5xNFnJQyBw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "#print(\"Loss\", calc_loss(ex_labels, decoder_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUM198fKQyEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(idx=None, flag=1):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(train_data))\n",
        "    \n",
        "    if flag == 1:\n",
        "      source_data = train_eng\n",
        "      target_tokenizer = spa_tokenizer\n",
        "      encoder = encoder1\n",
        "      decoder = decoder1\n",
        "      tmp0, tmp1 = train_data[idx][0], train_data[idx][1]\n",
        "    elif flag == 2:\n",
        "      source_data = train_spa\n",
        "      target_tokenizer = eng_tokenizer\n",
        "      encoder = encoder2\n",
        "      decoder = decoder2\n",
        "      tmp0, tmp1 = train_data[idx][1], train_data[idx][0] \n",
        "    elif flag == 3:\n",
        "      source_data = test_eng\n",
        "      target_tokenizer = spa_tokenizer\n",
        "      encoder = encoder1\n",
        "      decoder = decoder1\n",
        "      tmp0, tmp1 = test_data[idx][0], test_data[idx][1]\n",
        "    elif flag == 4:\n",
        "      source_data = input_spa\n",
        "      target_tokenizer = eng_tokenizer\n",
        "      encoder = encoder2\n",
        "      decoder = decoder2\n",
        "      tmp0, tmp1 = input_spa[idx][1], test_data[idx][0]       \n",
        "      \n",
        "    input_sent = source_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return tmp0, tmp1, translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7YSgbsvQyIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test code\n",
        "# input_sent, target_sent, translation = translate()\n",
        "# print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spcI0A4HWRQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HXX5F79WUIy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3. Train Model 1: from English to Spanish"
      ]
    },
    {
      "metadata": {
        "id": "Np7vJsGQWcin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder1(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder1(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder1.trainable_variables + decoder1.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHm1Riq8YH-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2587
        },
        "outputId": "9384c3cb-3bf1-4cab-b198-6ac3ad0d4df7"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = nepoch\n",
        "\n",
        "encoder1 = Encoder(eng_vocab_size)\n",
        "decoder1 = Decoder(spa_vocab_size)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder1.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.4409, Time 7.79 sec\n",
            "Input: <start> Though he had been in the hospital , he kept up with other students . <end>\n",
            "Target: <start> Aunque ha estado en el hospital , el mantuvo el ritmo de los demas estudiantes . <end>\n",
            "Translation: ¿ ¿ <end>\n",
            "\n",
            "Epoch #10, Loss 0.9816, Time 3.01 sec\n",
            "Input: <start> Both claims are false . <end>\n",
            "Target: <start> Ambas afirmaciones son falsas . <end>\n",
            "Translation: ¿ que se gusta , el dinero de la escuela . <end>\n",
            "\n",
            "Epoch #20, Loss 0.7861, Time 2.95 sec\n",
            "Input: <start> We ll meet in the theater . <end>\n",
            "Target: <start> Nos encontraremos en el teatro . <end>\n",
            "Translation: el se retrasa frecuentemente en la escuela . <end>\n",
            "\n",
            "Epoch #30, Loss 0.6302, Time 3.12 sec\n",
            "Input: <start> I did that willingly . <end>\n",
            "Target: <start> Lo hice porque quise . <end>\n",
            "Translation: tom no he hecho a que diga el tren . <end>\n",
            "\n",
            "Epoch #40, Loss 0.5040, Time 3.07 sec\n",
            "Input: <start> He gave me his word . <end>\n",
            "Target: <start> El me dio su palabra . <end>\n",
            "Translation: el se retrasa frecuentemente en la escuela . <end>\n",
            "\n",
            "Epoch #50, Loss 0.4080, Time 3.08 sec\n",
            "Input: <start> We measured the depth of the river . <end>\n",
            "Target: <start> Nosotros medimos la profundidad del rio . <end>\n",
            "Translation: ¿ que significa a ir a sus espaldas . <end>\n",
            "\n",
            "Epoch #60, Loss 0.3381, Time 2.90 sec\n",
            "Input: <start> He confessed his guilt . <end>\n",
            "Target: <start> El confeso su culpa . <end>\n",
            "Translation: el se retrasa frecuentemente en la escuela . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2727, Time 2.97 sec\n",
            "Input: <start> Can you believe it ? He s even lazier than me . <end>\n",
            "Target: <start> ¿ Te lo puedes creer ? El es todavia mas vago que yo . <end>\n",
            "Translation: ¿ estas ahi ? <end>\n",
            "\n",
            "Epoch #80, Loss 0.2298, Time 3.10 sec\n",
            "Input: <start> I got my bicycle repaired . <end>\n",
            "Target: <start> Mande mi bicicleta a arreglar . <end>\n",
            "Translation: ¿ que altura tiene el monte fuji ? <end>\n",
            "\n",
            "Epoch #90, Loss 0.2000, Time 3.00 sec\n",
            "Input: <start> How do you think that makes me feel ? <end>\n",
            "Target: <start> ¿ Como crees que me hace sentir eso ? <end>\n",
            "Translation: ¿ que significa eso ? <end>\n",
            "\n",
            "Epoch #100, Loss 0.1569, Time 3.11 sec\n",
            "Input: <start> She s adorable . <end>\n",
            "Target: <start> Ella es adorable . <end>\n",
            "Translation: ella me peino el cabello y esta intentado vender . <end>\n",
            "\n",
            "Epoch #110, Loss 0.1392, Time 3.11 sec\n",
            "Input: <start> He knows the truth . <end>\n",
            "Target: <start> El conoce la verdad . <end>\n",
            "Translation: el hombre se prendio a que te marches hoy ? <end>\n",
            "\n",
            "Epoch #120, Loss 0.1210, Time 3.16 sec\n",
            "Input: <start> Pick me up at . <end>\n",
            "Target: <start> Recogeme a las dos y media . <end>\n",
            "Translation: alguien tosio . <end>\n",
            "\n",
            "Epoch #130, Loss 0.0921, Time 3.06 sec\n",
            "Input: <start> They got married . <end>\n",
            "Target: <start> Ellos se casaron . <end>\n",
            "Translation: ellos se casaron . <end>\n",
            "\n",
            "Epoch #140, Loss 0.0793, Time 3.06 sec\n",
            "Input: <start> They took no part in the social revolution . <end>\n",
            "Target: <start> Ellos no tomaron parte en la revolucion social . <end>\n",
            "Translation: ellos no vieron nada . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0547, Time 2.90 sec\n",
            "Input: <start> There s nothing in my cup . <end>\n",
            "Target: <start> No hay nada en mi taza . <end>\n",
            "Translation: no estoy hecho de dinero . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0524, Time 2.87 sec\n",
            "Input: <start> Tom was baffled . <end>\n",
            "Target: <start> Tom estaba desorientado . <end>\n",
            "Translation: tom estaba desorientado . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0298, Time 3.17 sec\n",
            "Input: <start> There s no wind today . <end>\n",
            "Target: <start> Hoy no hace nada de viento . <end>\n",
            "Translation: hoy no hace nada de viento . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0247, Time 3.06 sec\n",
            "Input: <start> You talk too much . <end>\n",
            "Target: <start> Hablas demasiado . <end>\n",
            "Translation: hablas demasiado . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0266, Time 3.07 sec\n",
            "Input: <start> I want to hire you . <end>\n",
            "Target: <start> Te quiero contratar . <end>\n",
            "Translation: te quiero contratar . <end>\n",
            "\n",
            "Epoch #200, Loss 0.0120, Time 3.07 sec\n",
            "Input: <start> He did it right away . <end>\n",
            "Target: <start> Lo hizo en el acto . <end>\n",
            "Translation: lo hizo en el acto . <end>\n",
            "\n",
            "Epoch #210, Loss 0.0247, Time 3.02 sec\n",
            "Input: <start> I want to tell you something important . <end>\n",
            "Target: <start> Quiero decirte algo importante . <end>\n",
            "Translation: quiero decirte algo importante . <end>\n",
            "\n",
            "Epoch #220, Loss 0.0069, Time 3.05 sec\n",
            "Input: <start> There s no wind today . <end>\n",
            "Target: <start> Hoy no hace nada de viento . <end>\n",
            "Translation: hoy no hace nada de viento . <end>\n",
            "\n",
            "Epoch #230, Loss 0.0068, Time 3.05 sec\n",
            "Input: <start> Is it there ? <end>\n",
            "Target: <start> ¿ Esta ahi ? <end>\n",
            "Translation: ¿ esta ahi ? <end>\n",
            "\n",
            "Epoch #240, Loss 0.0047, Time 3.13 sec\n",
            "Input: <start> I had to pay a high interest . <end>\n",
            "Target: <start> Tenia que pagar mucho interes . <end>\n",
            "Translation: tenia que pagar mucho interes . <end>\n",
            "\n",
            "Epoch #250, Loss 0.0791, Time 3.07 sec\n",
            "Input: <start> Mary did it for free . <end>\n",
            "Target: <start> Mary lo hizo gratis . <end>\n",
            "Translation: mary lo hizo gratis . <end>\n",
            "\n",
            "Epoch #260, Loss 0.0086, Time 3.00 sec\n",
            "Input: <start> I am a bit drunk . <end>\n",
            "Target: <start> Estoy un poco borracho . <end>\n",
            "Translation: estoy un poco borracho . <end>\n",
            "\n",
            "Epoch #270, Loss 0.0043, Time 3.08 sec\n",
            "Input: <start> I admitted that I didn t do that . <end>\n",
            "Target: <start> Admiti que no lo hice . <end>\n",
            "Translation: admiti que no lo hice . <end>\n",
            "\n",
            "Epoch #280, Loss 0.0066, Time 3.10 sec\n",
            "Input: <start> Don t worry . I ll take care of it . <end>\n",
            "Target: <start> No te preocupes . Yo me hare cargo . <end>\n",
            "Translation: no te preocupes . yo me hare cargo . <end>\n",
            "\n",
            "Epoch #290, Loss 0.0023, Time 3.04 sec\n",
            "Input: <start> Is this price acceptable ? <end>\n",
            "Target: <start> ¿ Es aceptable el precio ? <end>\n",
            "Translation: ¿ es aceptable el precio ? <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OhGierZMQyK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f6cab0ff-092d-4a49-e8c2-51411611c398"
      },
      "cell_type": "code",
      "source": [
        "# Test code for BLEU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(20):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=69.51773116535472, counts=[161, 118, 92, 72], totals=[184, 164, 144, 124], precisions=[87.5, 71.95121951219512, 63.888888888888886, 58.064516129032256], bp=1.0, sys_len=184, ref_len=184)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7YyijjLcvu6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4. Train Model 2: translate from Spanish to English"
      ]
    },
    {
      "metadata": {
        "id": "L444gcl7e1Dn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1. Prepare data for model2\n"
      ]
    },
    {
      "metadata": {
        "id": "j4tL981we0H9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(train_eng.shape)\n",
        "target_labels[:,0:train_eng.shape[1] -1] = train_eng[:,1:]\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_spa, train_eng, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5bsG7DZjfMTy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Train Model2: from Spanish to English"
      ]
    },
    {
      "metadata": {
        "id": "NtJ1SGR-fLkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step2(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder2(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder2(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder2.trainable_variables + decoder2.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Ayomy6DQyOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2587
        },
        "outputId": "d3ec0503-d3fc-4c4d-cc88-b566dfe2a3a9"
      },
      "cell_type": "code",
      "source": [
        "encoder2 = Encoder(spa_vocab_size)\n",
        "decoder2 = Decoder(eng_vocab_size)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder2.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step2(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate(flag=2)\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.4788, Time 7.53 sec\n",
            "Input: <start> Tom soplo las velitas de su torta de cumpleanos . <end>\n",
            "Target: <start> Tom blew out the candles on his birthday cake . <end>\n",
            "Translation: i i you to . <end>\n",
            "\n",
            "Epoch #10, Loss 0.8787, Time 2.97 sec\n",
            "Input: <start> Acabo de volver a casa . <end>\n",
            "Target: <start> I just got back home . <end>\n",
            "Translation: i m not a bit and three years . <end>\n",
            "\n",
            "Epoch #20, Loss 0.6468, Time 2.83 sec\n",
            "Input: <start> Nunca dije eso . <end>\n",
            "Target: <start> I never said that . <end>\n",
            "Translation: i m not a bit time in the world . <end>\n",
            "\n",
            "Epoch #30, Loss 0.5148, Time 2.79 sec\n",
            "Input: <start> Nunca dije eso . <end>\n",
            "Target: <start> I never said that . <end>\n",
            "Translation: i m not a bit tired . <end>\n",
            "\n",
            "Epoch #40, Loss 0.3968, Time 2.72 sec\n",
            "Input: <start> Tom se preguntaba cuantas veces deberia decirle a Maria que limpiara su pieza antes de que al fin lo hiciera . <end>\n",
            "Target: <start> Tom wondered how many times he d have to tell Mary to clean her room before she finally did it . <end>\n",
            "Translation: tom is a pacifist . <end>\n",
            "\n",
            "Epoch #50, Loss 0.3061, Time 2.74 sec\n",
            "Input: <start> Tengo pocos libros . <end>\n",
            "Target: <start> I have few books . <end>\n",
            "Translation: i m not a bit tired . <end>\n",
            "\n",
            "Epoch #60, Loss 0.2450, Time 2.76 sec\n",
            "Input: <start> Decidi ser medico . <end>\n",
            "Target: <start> I decided to be a doctor . <end>\n",
            "Translation: i m not a bit tired . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2081, Time 2.76 sec\n",
            "Input: <start> ¿ Como vas a solucionar este problema ? <end>\n",
            "Target: <start> How are you going to solve this problem ? <end>\n",
            "Translation: we ll meet in the theater . <end>\n",
            "\n",
            "Epoch #80, Loss 0.1726, Time 2.81 sec\n",
            "Input: <start> ¿ Hay algo que pueda hacer por usted ? <end>\n",
            "Target: <start> Is there anything that I can do for you ? <end>\n",
            "Translation: is there anyone who wants some more pie ? <end>\n",
            "\n",
            "Epoch #90, Loss 0.1277, Time 2.78 sec\n",
            "Input: <start> Asi fue como llegue a conocerla . <end>\n",
            "Target: <start> That s how I came to know her . <end>\n",
            "Translation: that s between tom and me . <end>\n",
            "\n",
            "Epoch #100, Loss 0.0948, Time 2.77 sec\n",
            "Input: <start> En realidad el nunca visito America . <end>\n",
            "Target: <start> He hasn t actually been to America . <end>\n",
            "Translation: he hasn t actually been to america . <end>\n",
            "\n",
            "Epoch #110, Loss 0.0744, Time 2.79 sec\n",
            "Input: <start> Ella dio luz a su primer hijo a los veinte anos de edad . <end>\n",
            "Target: <start> She gave birth to her first child at twenty years old . <end>\n",
            "Translation: she didn t take part in our conversation . <end>\n",
            "\n",
            "Epoch #120, Loss 0.0528, Time 2.77 sec\n",
            "Input: <start> Aqui esta el ! <end>\n",
            "Target: <start> Here he is ! <end>\n",
            "Translation: here he is ! <end>\n",
            "\n",
            "Epoch #130, Loss 0.0378, Time 2.83 sec\n",
            "Input: <start> Hice que mi perro se acueste . <end>\n",
            "Target: <start> I made my dog lie down . <end>\n",
            "Translation: i made my dog lie down . <end>\n",
            "\n",
            "Epoch #140, Loss 0.0276, Time 2.89 sec\n",
            "Input: <start> No habia nada que hacer salvo esperar a la manana siguiente . <end>\n",
            "Target: <start> There was nothing to do but wait until the next morning . <end>\n",
            "Translation: there was nothing to do but wait until the next morning . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0212, Time 2.84 sec\n",
            "Input: <start> Ella nunca habia estado tan orgullosa de si misma . <end>\n",
            "Target: <start> She had never been so proud of herself . <end>\n",
            "Translation: she had never been so proud of herself . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0169, Time 2.83 sec\n",
            "Input: <start> Me quede dormido y llegue tarde al colegio . <end>\n",
            "Target: <start> I overslept and was late for school . <end>\n",
            "Translation: i overslept and was late for school . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0088, Time 2.77 sec\n",
            "Input: <start> Asegurese de decirle a Tom a que horas debe estar aqui . <end>\n",
            "Target: <start> Make sure to tell Tom what time to be here . <end>\n",
            "Translation: make sure to tell tom what time to be here . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0055, Time 2.77 sec\n",
            "Input: <start> A veces mentimos para no lastimar los sentimientos de los demas . <end>\n",
            "Target: <start> Sometimes we lie to keep from hurting someone else s feelings . <end>\n",
            "Translation: sometimes we lie to keep from hurting someone else s feelings . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0098, Time 2.82 sec\n",
            "Input: <start> Mi mama le compro un paraguas amarillo a mi hermano . <end>\n",
            "Target: <start> My mother bought my brother a yellow umbrella . <end>\n",
            "Translation: my mother bought my brother a yellow umbrella . <end>\n",
            "\n",
            "Epoch #200, Loss 0.0028, Time 2.84 sec\n",
            "Input: <start> El confeso su culpa . <end>\n",
            "Target: <start> He confessed his guilt . <end>\n",
            "Translation: he confessed his guilt . <end>\n",
            "\n",
            "Epoch #210, Loss 0.0020, Time 2.82 sec\n",
            "Input: <start> Su hija mayor se ha casado . <end>\n",
            "Target: <start> Her oldest daughter got married . <end>\n",
            "Translation: her oldest daughter got married . <end>\n",
            "\n",
            "Epoch #220, Loss 0.0015, Time 2.79 sec\n",
            "Input: <start> No te corresponde a ti tomar la decision . <end>\n",
            "Target: <start> That s not your decision to make . <end>\n",
            "Translation: that s not your decision to make . <end>\n",
            "\n",
            "Epoch #230, Loss 0.0097, Time 2.79 sec\n",
            "Input: <start> Tengo sueno . <end>\n",
            "Target: <start> I feel sleepy . <end>\n",
            "Translation: i feel sleepy . <end>\n",
            "\n",
            "Epoch #240, Loss 0.0015, Time 2.75 sec\n",
            "Input: <start> Tenemos un perro , un gato y tres canarios . <end>\n",
            "Target: <start> We have a dog , a cat and three canaries . <end>\n",
            "Translation: we have a dog , a cat and three canaries . <end>\n",
            "\n",
            "Epoch #250, Loss 0.0010, Time 2.76 sec\n",
            "Input: <start> Tom no tiene mal aspecto . <end>\n",
            "Target: <start> Tom isn t bad looking . <end>\n",
            "Translation: tom isn t bad looking . <end>\n",
            "\n",
            "Epoch #260, Loss 0.0008, Time 2.69 sec\n",
            "Input: <start> Tom oyo a alguien tararear su melodia favorita . <end>\n",
            "Target: <start> Tom heard someone humming his favorite tune . <end>\n",
            "Translation: tom heard someone humming his favorite tune . <end>\n",
            "\n",
            "Epoch #270, Loss 0.0006, Time 2.72 sec\n",
            "Input: <start> Tenemos un perro , un gato y tres canarios . <end>\n",
            "Target: <start> We have a dog , a cat and three canaries . <end>\n",
            "Translation: we have a dog , a cat and three canaries . <end>\n",
            "\n",
            "Epoch #280, Loss 0.0005, Time 2.71 sec\n",
            "Input: <start> Es una familia acomodada . <end>\n",
            "Target: <start> It s a well to do family . <end>\n",
            "Translation: it s a well to do family . <end>\n",
            "\n",
            "Epoch #290, Loss 0.0009, Time 2.66 sec\n",
            "Input: <start> Por favor , deja de hablar . <end>\n",
            "Target: <start> Please stop talking . <end>\n",
            "Translation: please stop talking . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yk3deGx8fKMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "beffc68c-267a-471f-eb53-13b1a28056b1"
      },
      "cell_type": "code",
      "source": [
        "# Test code for BLEU score\n",
        "references, hypotheses = [], []\n",
        "\n",
        "for i in range(20):\n",
        "  input_sent, target_sent, translation = translate(flag=2)\n",
        "  references.append(target_sent)\n",
        "  hypotheses.append(\"<start> \" + translation)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses, [references])\n",
        "print(results)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=76.13470549829283, counts=[181, 139, 118, 98], totals=[203, 183, 163, 143], precisions=[89.16256157635468, 75.95628415300547, 72.39263803680981, 68.53146853146853], bp=1.0, sys_len=203, ref_len=203)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WqSWEDDzfKPq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLgzr_V2hZ1n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5. Back-translate\n",
        "Use your two models to translate a sentence from English to Spanish, and then back to English. Compare the original sentence, and the back-translated sentence. Repeat this using an evaluation corpus of 1,000 sentences, and report the BLEU score."
      ]
    },
    {
      "metadata": {
        "id": "ZuiyrsAUOvyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.1. Preprocess test data"
      ]
    },
    {
      "metadata": {
        "id": "vU2Ifd1rhmZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = shuffled_data[selected_id[ntrain:], :]\n",
        "test_data = [(preprocess(eng), preprocess(spa)) for (eng, spa) in test_data]\n",
        "#print(train_data[0])\n",
        "test_eng, test_spa = list(zip(*test_data))\n",
        "test_eng = eng_tokenizer.texts_to_sequences(test_eng)\n",
        "test_eng = tf.keras.preprocessing.sequence.pad_sequences(test_eng, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwRO9rDnO0UL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.2. Using Model 1 to translate test data from English to Spanish."
      ]
    },
    {
      "metadata": {
        "id": "oFmTgv5qfKTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "middle_spa = []\n",
        "origin_eng = []\n",
        "for i in range(ntest):\n",
        "  input_sent, target_sent, translation = translate(idx=i, flag=3)\n",
        "  #print(input_sent)\n",
        "  origin_eng.append(input_sent)\n",
        "  middle_spa.append(translation[:-5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63IpkexsO9Sk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.3. Using Model 2 to translate the output from Model 1 back to English"
      ]
    },
    {
      "metadata": {
        "id": "gi3v5GaKBhgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_spa = spa_tokenizer.texts_to_sequences(middle_spa)\n",
        "input_spa = tf.keras.preprocessing.sequence.pad_sequences(input_spa, padding='post')\n",
        "#print(input_spa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYyzBqvEhmeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "back_eng = []\n",
        "for i in range(ntest):\n",
        "  input_sent, target_sent, translation = translate(idx=i, flag=4)\n",
        "  #print(translation)\n",
        "  back_eng.append(\"<start> \" + translation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4LvXYUrPGT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.4. Calculate BLEU"
      ]
    },
    {
      "metadata": {
        "id": "b5M_5-z9Gu3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "af12bedb-d357-4a7f-cafc-d8f755e9ddc5"
      },
      "cell_type": "code",
      "source": [
        "results = sacrebleu.raw_corpus_bleu(back_eng, [origin_eng])\n",
        "print(results)  "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=3.411137451052326, counts=[356, 107, 6, 3], totals=[1001, 901, 801, 701], precisions=[35.56443556443556, 11.875693673695894, 0.7490636704119851, 0.42796005706134094], bp=1.0, sys_len=1001, ref_len=954)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}