{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a2-jq2282.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingQian87/AppliedDL/blob/master/a2_jq2282.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5k5rSsb1JCjS"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1. Train a model on an existing dataset\n",
        "\n",
        "### 1. Classify images using transfer learning from mini-flowers dataset\n",
        "Download the ​mini-flowers​ dataset. This contains 1,500 images of five different types of flowers. Modify one of the above notebooks to classify these images using transfer learning. How accurate of a model can you train? ​Note: the example notebooks are for binary classification. You will need to change the output layer shape, activation, and loss function for multiclass classification."
      ]
    },
    {
      "metadata": {
        "id": "GY6V6CUeI61y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUxC_hBqLO77",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step1. Load and explore data"
      ]
    },
    {
      "metadata": {
        "id": "PejQFoIuCkxj",
        "colab_type": "code",
        "outputId": "ba20e762-3e55-45aa-9147-c1d51e15166e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N1bD1s6uEmXD",
        "colab_type": "code",
        "outputId": "e270d273-c9ab-46d2-be59-9fd4f510340e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "local_zip = '/content/mini_flowers.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "!ls '/tmp/'\n",
        "!ls '/tmp/train/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drivefs_ipc.0  drivefs_ipc.0_shell  LICENSE.txt  train\tval\n",
            "daisy  dandelion  roses  sunflowers  tulips\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_j1Y8XwE9V9",
        "colab_type": "code",
        "outputId": "fc1abd76-1bb0-416b-80d4-5b34ac008638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "base_dir = '/tmp'\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "total_train = 0\n",
        "for i in os.listdir(train_dir):\n",
        "  tmp = len(os.listdir(os.path.join(train_dir, i)))\n",
        "  print('Training ', i, ' images:', tmp)\n",
        "  total_train += tmp\n",
        " \n",
        "total_val = 0\n",
        "for i in os.listdir(validation_dir):\n",
        "  tmp = len(os.listdir(os.path.join(validation_dir, i)))\n",
        "  print('Validation ', i, ' images:', tmp)\n",
        "  total_val += tmp\n",
        "  \n",
        "print(\"--\")\n",
        "\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training  roses  images: 200\n",
            "Training  tulips  images: 200\n",
            "Training  dandelion  images: 200\n",
            "Training  daisy  images: 200\n",
            "Training  sunflowers  images: 200\n",
            "Validation  roses  images: 100\n",
            "Validation  tulips  images: 100\n",
            "Validation  dandelion  images: 100\n",
            "Validation  daisy  images: 100\n",
            "Validation  sunflowers  images: 100\n",
            "--\n",
            "Total training images: 1000\n",
            "Total validation images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vsZUJvMZPA9h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step2. Use VGG model"
      ]
    },
    {
      "metadata": {
        "id": "VnSdEPTyJE6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "1bbcdc5d-676b-4c25-8ba0-129e067351fd"
      },
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(150, 150, 3))\n",
        "conv_base.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rJCf0YZXJE3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Images be resized to TARGET_SHAPE * TARGET_SHAPE pixels as they're read off the disk\n",
        "TARGET_SHAPE = 150\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGl6bma9JE0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "89b5d354-ced8-4501-b973-0c9dfec50630"
      },
      "cell_type": "code",
      "source": [
        "# Cache activations for our training and validation data\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))#from block5 of VGG16\n",
        "    labels = np.zeros(shape=(sample_count, 5))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(TARGET_SHAPE, TARGET_SHAPE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "      \n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        # print(features_batch.shape)\n",
        "        # (32, 4, 4, 512)\n",
        "        # Think: batch_size, rows, cols, channels\n",
        "        \n",
        "        features[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = features_batch\n",
        "        labels[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = labels_batch\n",
        "        i += 1\n",
        "        if i * BATCH_SIZE >= sample_count:\n",
        "            # Note that since generators yield data indefinitely in a loop,\n",
        "            # we must `break` after every image has been seen once.\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_dir, 1000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 500)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 5 classes.\n",
            "Found 500 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9elBS4fYNgoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1754
        },
        "outputId": "8a014108-cb8a-4b2d-cae1-1f8768a422d2"
      },
      "cell_type": "code",
      "source": [
        "FLATTENED_SHAPE = 4 * 4 * 512\n",
        "\n",
        "train_features = np.reshape(train_features, (total_train, FLATTENED_SHAPE))\n",
        "validation_features = np.reshape(validation_features, (total_val, FLATTENED_SHAPE))\n",
        "EPOCHS = 50\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=FLATTENED_SHAPE))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 500 samples\n",
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 1s 580us/sample - loss: 1.3272 - acc: 0.5230 - val_loss: 0.7587 - val_acc: 0.7380\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 0s 305us/sample - loss: 0.6909 - acc: 0.7340 - val_loss: 0.7141 - val_acc: 0.7060\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 0s 315us/sample - loss: 0.5614 - acc: 0.7890 - val_loss: 0.5974 - val_acc: 0.7900\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 0s 302us/sample - loss: 0.4079 - acc: 0.8610 - val_loss: 0.6661 - val_acc: 0.7560\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 0s 304us/sample - loss: 0.3309 - acc: 0.8830 - val_loss: 0.6437 - val_acc: 0.7600\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 0s 318us/sample - loss: 0.2580 - acc: 0.9110 - val_loss: 0.6292 - val_acc: 0.7820\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 0s 302us/sample - loss: 0.1741 - acc: 0.9420 - val_loss: 0.6143 - val_acc: 0.7720\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 0s 305us/sample - loss: 0.1546 - acc: 0.9590 - val_loss: 0.6444 - val_acc: 0.7740\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 0s 320us/sample - loss: 0.1075 - acc: 0.9720 - val_loss: 0.5796 - val_acc: 0.7920\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 0s 301us/sample - loss: 0.0918 - acc: 0.9770 - val_loss: 0.6629 - val_acc: 0.7780\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 0s 306us/sample - loss: 0.0929 - acc: 0.9770 - val_loss: 0.6118 - val_acc: 0.8100\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 0s 304us/sample - loss: 0.0615 - acc: 0.9900 - val_loss: 0.7548 - val_acc: 0.7680\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 0s 316us/sample - loss: 0.0572 - acc: 0.9880 - val_loss: 0.6527 - val_acc: 0.7940\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 0s 308us/sample - loss: 0.0520 - acc: 0.9900 - val_loss: 0.7160 - val_acc: 0.7860\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 0s 301us/sample - loss: 0.0509 - acc: 0.9870 - val_loss: 0.6360 - val_acc: 0.8000\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 0s 333us/sample - loss: 0.0464 - acc: 0.9900 - val_loss: 0.6769 - val_acc: 0.7980\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 0s 307us/sample - loss: 0.0448 - acc: 0.9870 - val_loss: 0.6878 - val_acc: 0.8060\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 0s 310us/sample - loss: 0.0405 - acc: 0.9940 - val_loss: 0.7979 - val_acc: 0.7660\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 0s 317us/sample - loss: 0.0342 - acc: 0.9930 - val_loss: 0.7734 - val_acc: 0.7920\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 0s 301us/sample - loss: 0.0235 - acc: 0.9980 - val_loss: 0.7226 - val_acc: 0.7940\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 0s 302us/sample - loss: 0.0215 - acc: 0.9960 - val_loss: 0.6956 - val_acc: 0.7980\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 0s 315us/sample - loss: 0.0240 - acc: 0.9960 - val_loss: 0.7794 - val_acc: 0.7880\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 0s 301us/sample - loss: 0.0251 - acc: 0.9970 - val_loss: 0.8755 - val_acc: 0.7720\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 0s 313us/sample - loss: 0.0223 - acc: 0.9970 - val_loss: 0.6856 - val_acc: 0.8120\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 0s 306us/sample - loss: 0.0219 - acc: 0.9970 - val_loss: 0.7683 - val_acc: 0.7920\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 0s 310us/sample - loss: 0.0227 - acc: 0.9970 - val_loss: 0.7474 - val_acc: 0.7900\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 0s 301us/sample - loss: 0.0224 - acc: 0.9980 - val_loss: 0.8709 - val_acc: 0.7800\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 0s 303us/sample - loss: 0.0279 - acc: 0.9940 - val_loss: 0.8569 - val_acc: 0.7800\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 0s 322us/sample - loss: 0.0124 - acc: 0.9990 - val_loss: 0.8038 - val_acc: 0.8020\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - 0s 303us/sample - loss: 0.0112 - acc: 0.9980 - val_loss: 0.8386 - val_acc: 0.7980\n",
            "Epoch 31/50\n",
            "1000/1000 [==============================] - 0s 306us/sample - loss: 0.0159 - acc: 0.9960 - val_loss: 0.8015 - val_acc: 0.7980\n",
            "Epoch 32/50\n",
            "1000/1000 [==============================] - 0s 315us/sample - loss: 0.0238 - acc: 0.9950 - val_loss: 0.8684 - val_acc: 0.7860\n",
            "Epoch 33/50\n",
            "1000/1000 [==============================] - 0s 308us/sample - loss: 0.0189 - acc: 0.9950 - val_loss: 0.8843 - val_acc: 0.7880\n",
            "Epoch 34/50\n",
            "1000/1000 [==============================] - 0s 306us/sample - loss: 0.0249 - acc: 0.9940 - val_loss: 0.8430 - val_acc: 0.7920\n",
            "Epoch 35/50\n",
            "1000/1000 [==============================] - 0s 325us/sample - loss: 0.0670 - acc: 0.9760 - val_loss: 0.8119 - val_acc: 0.7880\n",
            "Epoch 36/50\n",
            "1000/1000 [==============================] - 0s 313us/sample - loss: 0.0842 - acc: 0.9780 - val_loss: 1.0650 - val_acc: 0.7360\n",
            "Epoch 37/50\n",
            "1000/1000 [==============================] - 0s 307us/sample - loss: 0.0641 - acc: 0.9800 - val_loss: 0.8506 - val_acc: 0.7800\n",
            "Epoch 38/50\n",
            "1000/1000 [==============================] - 0s 310us/sample - loss: 0.0425 - acc: 0.9880 - val_loss: 0.8540 - val_acc: 0.7780\n",
            "Epoch 39/50\n",
            "1000/1000 [==============================] - 0s 315us/sample - loss: 0.0225 - acc: 0.9950 - val_loss: 0.9057 - val_acc: 0.7800\n",
            "Epoch 40/50\n",
            "1000/1000 [==============================] - 0s 301us/sample - loss: 0.0196 - acc: 0.9950 - val_loss: 0.9465 - val_acc: 0.7880\n",
            "Epoch 41/50\n",
            "1000/1000 [==============================] - 0s 313us/sample - loss: 0.0137 - acc: 0.9980 - val_loss: 0.8630 - val_acc: 0.7920\n",
            "Epoch 42/50\n",
            "1000/1000 [==============================] - 0s 312us/sample - loss: 0.0124 - acc: 0.9990 - val_loss: 0.9862 - val_acc: 0.7840\n",
            "Epoch 43/50\n",
            "1000/1000 [==============================] - 0s 303us/sample - loss: 0.0135 - acc: 0.9970 - val_loss: 0.9999 - val_acc: 0.7860\n",
            "Epoch 44/50\n",
            "1000/1000 [==============================] - 0s 306us/sample - loss: 0.0207 - acc: 0.9940 - val_loss: 0.9543 - val_acc: 0.7900\n",
            "Epoch 45/50\n",
            "1000/1000 [==============================] - 0s 318us/sample - loss: 0.0159 - acc: 0.9960 - val_loss: 0.9740 - val_acc: 0.7740\n",
            "Epoch 46/50\n",
            "1000/1000 [==============================] - 0s 306us/sample - loss: 0.0169 - acc: 0.9970 - val_loss: 0.9403 - val_acc: 0.7880\n",
            "Epoch 47/50\n",
            "1000/1000 [==============================] - 0s 327us/sample - loss: 0.0176 - acc: 0.9950 - val_loss: 0.9741 - val_acc: 0.7760\n",
            "Epoch 48/50\n",
            "1000/1000 [==============================] - 0s 315us/sample - loss: 0.0199 - acc: 0.9950 - val_loss: 0.8844 - val_acc: 0.7860\n",
            "Epoch 49/50\n",
            "1000/1000 [==============================] - 0s 310us/sample - loss: 0.0199 - acc: 0.9940 - val_loss: 0.9297 - val_acc: 0.7880\n",
            "Epoch 50/50\n",
            "1000/1000 [==============================] - 0s 310us/sample - loss: 0.0237 - acc: 0.9930 - val_loss: 1.0076 - val_acc: 0.7700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQHjT6MZKb8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "65b8fb8e-f529-4ebf-fdaf-af896691517d"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 18,912,069\n",
            "Trainable params: 18,912,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jkjo2n4IKq8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdb52fcd-128e-4646-d563-ce9c84578b62"
      },
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False\n",
        "image_gen_train = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE, \n",
        "    directory=train_dir, \n",
        "    shuffle=True, \n",
        "    target_size=(TARGET_SHAPE,TARGET_SHAPE),\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Validation data should not be augmented!\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = image_gen_val.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE, \n",
        "    directory=validation_dir, \n",
        "    target_size=(TARGET_SHAPE, TARGET_SHAPE),\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 5 classes.\n",
            "Found 500 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w94GQNosLITv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        },
        "outputId": "4b95b4dd-9442-425c-c32d-e279b4f4aa86"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 50\n",
        "history2 = model.fit_generator(\n",
        "      train_data_gen,\n",
        "      steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "      epochs=EPOCHS,\n",
        "      validation_data=val_data_gen,\n",
        "      validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))),\n",
        "      verbose=2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 3s 183ms/step - loss: 0.8510 - acc: 0.6900\n",
            " - 11s - loss: 1.3851 - acc: 0.5270 - val_loss: 0.8510 - val_acc: 0.6900\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.7063 - acc: 0.7280\n",
            " - 10s - loss: 0.7479 - acc: 0.7210 - val_loss: 0.7063 - val_acc: 0.7280\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.7124 - acc: 0.7500\n",
            " - 10s - loss: 0.6651 - acc: 0.7580 - val_loss: 0.7124 - val_acc: 0.7500\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.8221 - acc: 0.7040\n",
            " - 10s - loss: 0.6568 - acc: 0.7680 - val_loss: 0.8221 - val_acc: 0.7040\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.6901 - acc: 0.7560\n",
            " - 10s - loss: 0.6249 - acc: 0.7680 - val_loss: 0.6901 - val_acc: 0.7560\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.5593 - acc: 0.8160\n",
            " - 10s - loss: 0.5753 - acc: 0.7970 - val_loss: 0.5593 - val_acc: 0.8160\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.5703 - acc: 0.7960\n",
            " - 10s - loss: 0.4965 - acc: 0.8210 - val_loss: 0.5703 - val_acc: 0.7960\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.6882 - acc: 0.7900\n",
            " - 10s - loss: 0.4804 - acc: 0.8190 - val_loss: 0.6882 - val_acc: 0.7900\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7597 - acc: 0.7480\n",
            " - 10s - loss: 0.4285 - acc: 0.8440 - val_loss: 0.7597 - val_acc: 0.7480\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.6032 - acc: 0.7920\n",
            " - 10s - loss: 0.4136 - acc: 0.8490 - val_loss: 0.6032 - val_acc: 0.7920\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.6098 - acc: 0.7960\n",
            " - 10s - loss: 0.3871 - acc: 0.8570 - val_loss: 0.6098 - val_acc: 0.7960\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.6409 - acc: 0.7860\n",
            " - 10s - loss: 0.4248 - acc: 0.8570 - val_loss: 0.6409 - val_acc: 0.7860\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.7669 - acc: 0.7240\n",
            " - 10s - loss: 0.3780 - acc: 0.8510 - val_loss: 0.7669 - val_acc: 0.7240\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.6214 - acc: 0.8000\n",
            " - 10s - loss: 0.3981 - acc: 0.8520 - val_loss: 0.6214 - val_acc: 0.8000\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.5479 - acc: 0.8120\n",
            " - 10s - loss: 0.3491 - acc: 0.8590 - val_loss: 0.5479 - val_acc: 0.8120\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.6399 - acc: 0.7920\n",
            " - 10s - loss: 0.3119 - acc: 0.8890 - val_loss: 0.6399 - val_acc: 0.7920\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.5556 - acc: 0.8160\n",
            " - 10s - loss: 0.3247 - acc: 0.8740 - val_loss: 0.5556 - val_acc: 0.8160\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.5819 - acc: 0.8200\n",
            " - 10s - loss: 0.3209 - acc: 0.8720 - val_loss: 0.5819 - val_acc: 0.8200\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.6067 - acc: 0.7960\n",
            " - 10s - loss: 0.2932 - acc: 0.8900 - val_loss: 0.6067 - val_acc: 0.7960\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.6842 - acc: 0.7780\n",
            " - 10s - loss: 0.3290 - acc: 0.8760 - val_loss: 0.6842 - val_acc: 0.7780\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.6274 - acc: 0.7980\n",
            " - 10s - loss: 0.3116 - acc: 0.8840 - val_loss: 0.6274 - val_acc: 0.7980\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.5778 - acc: 0.8240\n",
            " - 10s - loss: 0.2782 - acc: 0.8990 - val_loss: 0.5778 - val_acc: 0.8240\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.9436 - acc: 0.7420\n",
            " - 10s - loss: 0.2632 - acc: 0.9070 - val_loss: 0.9436 - val_acc: 0.7420\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.6890 - acc: 0.7820\n",
            " - 10s - loss: 0.3045 - acc: 0.8940 - val_loss: 0.6890 - val_acc: 0.7820\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7077 - acc: 0.7820\n",
            " - 10s - loss: 0.2751 - acc: 0.9000 - val_loss: 0.7077 - val_acc: 0.7820\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.6696 - acc: 0.7920\n",
            " - 10s - loss: 0.2593 - acc: 0.9000 - val_loss: 0.6696 - val_acc: 0.7920\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.6601 - acc: 0.7960\n",
            " - 10s - loss: 0.2407 - acc: 0.9110 - val_loss: 0.6601 - val_acc: 0.7960\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.6966 - acc: 0.7840\n",
            " - 10s - loss: 0.2267 - acc: 0.9230 - val_loss: 0.6966 - val_acc: 0.7840\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 3s 161ms/step - loss: 0.6826 - acc: 0.7700\n",
            " - 10s - loss: 0.2682 - acc: 0.8980 - val_loss: 0.6826 - val_acc: 0.7700\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.9348 - acc: 0.7500\n",
            " - 10s - loss: 0.2172 - acc: 0.9190 - val_loss: 0.9348 - val_acc: 0.7500\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.6066 - acc: 0.8240\n",
            " - 10s - loss: 0.2311 - acc: 0.9180 - val_loss: 0.6066 - val_acc: 0.8240\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.7445 - acc: 0.8300\n",
            " - 10s - loss: 0.1974 - acc: 0.9320 - val_loss: 0.7445 - val_acc: 0.8300\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.6415 - acc: 0.8180\n",
            " - 10s - loss: 0.2406 - acc: 0.9030 - val_loss: 0.6415 - val_acc: 0.8180\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.6063 - acc: 0.8420\n",
            " - 10s - loss: 0.1725 - acc: 0.9340 - val_loss: 0.6063 - val_acc: 0.8420\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7007 - acc: 0.8100\n",
            " - 10s - loss: 0.2222 - acc: 0.9170 - val_loss: 0.7007 - val_acc: 0.8100\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7586 - acc: 0.8100\n",
            " - 10s - loss: 0.1820 - acc: 0.9330 - val_loss: 0.7586 - val_acc: 0.8100\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.7751 - acc: 0.7940\n",
            " - 10s - loss: 0.1756 - acc: 0.9400 - val_loss: 0.7751 - val_acc: 0.7940\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.7698 - acc: 0.7800\n",
            " - 10s - loss: 0.2353 - acc: 0.9260 - val_loss: 0.7698 - val_acc: 0.7800\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7108 - acc: 0.7940\n",
            " - 10s - loss: 0.2025 - acc: 0.9310 - val_loss: 0.7108 - val_acc: 0.7940\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7454 - acc: 0.8020\n",
            " - 10s - loss: 0.2274 - acc: 0.9280 - val_loss: 0.7454 - val_acc: 0.8020\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 3s 160ms/step - loss: 0.5655 - acc: 0.8340\n",
            " - 10s - loss: 0.2452 - acc: 0.9100 - val_loss: 0.5655 - val_acc: 0.8340\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7344 - acc: 0.7900\n",
            " - 10s - loss: 0.1814 - acc: 0.9270 - val_loss: 0.7344 - val_acc: 0.7900\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.7916 - acc: 0.7920\n",
            " - 10s - loss: 0.1549 - acc: 0.9400 - val_loss: 0.7916 - val_acc: 0.7920\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.7788 - acc: 0.7860\n",
            " - 10s - loss: 0.1688 - acc: 0.9390 - val_loss: 0.7788 - val_acc: 0.7860\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7199 - acc: 0.8120\n",
            " - 10s - loss: 0.1411 - acc: 0.9580 - val_loss: 0.7199 - val_acc: 0.8120\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.7549 - acc: 0.8020\n",
            " - 10s - loss: 0.1346 - acc: 0.9560 - val_loss: 0.7549 - val_acc: 0.8020\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 3s 162ms/step - loss: 0.7514 - acc: 0.8100\n",
            " - 10s - loss: 0.1216 - acc: 0.9600 - val_loss: 0.7514 - val_acc: 0.8100\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.6939 - acc: 0.8180\n",
            " - 10s - loss: 0.1475 - acc: 0.9440 - val_loss: 0.6939 - val_acc: 0.8180\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.7422 - acc: 0.7960\n",
            " - 10s - loss: 0.1578 - acc: 0.9430 - val_loss: 0.7422 - val_acc: 0.7960\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.7482 - acc: 0.8000\n",
            " - 10s - loss: 0.1467 - acc: 0.9560 - val_loss: 0.7482 - val_acc: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "926Dy7DGLIHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "604fdf89-ae21-40b0-8e0a-36268390fede"
      },
      "cell_type": "code",
      "source": [
        "acc = history2.history['acc']\n",
        "val_acc = history2.history['val_acc']\n",
        "\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, EPOCHS+1)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAHhCAYAAABZSgYOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aRjleNOesSjA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Run experiments using at least two pretrained convolutional bases\n",
        "Run experiments using at least two pretrained convolutional bases and compare your results. Include a short, informal write-up (using bullet points is fine). What differences do you see, and why? Read the associated papers to learn more about the networks you’re using, linked from the API doc."
      ]
    },
    {
      "metadata": {
        "id": "rMPS2zPVw2ee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model 1: ResNet50"
      ]
    },
    {
      "metadata": {
        "id": "fPExIll2JExU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6463
        },
        "outputId": "fc9c6f31-c838-43a0-f75e-284d18bb2ad9"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "conv_base2 = ResNet50(weights='imagenet',include_top=False, input_shape=(150, 150, 3))\n",
        "conv_base2.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 75, 75, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 75, 75, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 38, 38, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 38, 38, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 38, 38, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 38, 38, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 38, 38, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 38, 38, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 38, 38, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 19, 19, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 19, 19, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 19, 19, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 10, 10, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 10, 10, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 10, 10, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 10, 10, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 10, 10, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 10, 10, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 10, 10, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 5, 5, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 5, 5, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 5, 5, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 5, 5, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K-b720hIJEt6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1y6By_UPJEqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSPKrD3YJEg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "alemr4mrwl-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Part 2 ​(70 points)​: ​Train a model to recognize landmarks on Columbia’s campus.\n",
        "\n",
        "collect a dataset containing images of three landmarks on\n",
        "Columbia’s campus (​example​), and train a model to identify them."
      ]
    },
    {
      "metadata": {
        "id": "XaeFjr84xDOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Collect a dataset of at least three landmarks. Your dataset should include at least 100 images of each in train, 50 in validation, and 25 in test (using more images is fine). You can randomly shuffle your dataset to create these splits.\n",
        "2. Write a model to classify your dataset using transfer learning. Run an experiment and report your results. What do you find?\n",
        "3. Next, how small of a model (in terms of the number of parameters) can you write to classify these images reasonably well? Explore the available pretrained ​models​, and see if any are suitable. Run an experiment and report your results."
      ]
    },
    {
      "metadata": {
        "id": "hI7e4zvLVe0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUt8F2CKVe4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lJmIcL1Ve7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IVDzAxcncVNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zi5EWRLuddqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZG_sJBKdU1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fewn98hqdNlp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-CqCe63edNpk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}